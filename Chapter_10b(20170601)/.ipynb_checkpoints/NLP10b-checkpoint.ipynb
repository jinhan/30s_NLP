{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Analyzing the Meaning of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each phrase structure rule is supplemented with a recipe for constructing a value for the feature 'sem'.\n",
    "\n",
    "predicates\n",
    "- Angus walks -> walk(angus) : unary predicate\n",
    "- Angus sees Bertie -> see(angus, bertie) : binary predicate\n",
    "\n",
    "basic types\n",
    "- e is the type of entities (= 명사?)\n",
    "- t is the type of formulas (= 동사?)\n",
    "- 〈e, t〉 is the type of expressions from entities to truth values, namely unary predicates. (= 절?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4   The Semantics of English Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1   Compositional Semantics in Feature-Based Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 문장의 논리적 형태(logical form)을 구성한다. 이것을 하기위한 guiding idea는 **Principle of Compositionality**.\n",
    "\n",
    "**Principle of Compositionality**: The meaning of a whole is a function of the meanings of the parts and of the way they are syntactically combined.\n",
    "\n",
    "(전체의 의미는 각 구성요소들의 의미와 그것들이 통사론적으로 결합된 방식의 작용이다.)\n",
    "\n",
    "우리의 목표는 파싱(parsing)과 의미론적 표현(semantic representation)을 부드럽게 결합시키는 것. 즉, 다음 그림과 같은 것을 구성하는 것이다. \n",
    "\n",
    "<img src = \"images/goal.png\">\n",
    "\n",
    "- S[SEM=<?vp(?np)>] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "- VP[SEM=?v] -> IV[SEM=?v]\n",
    "- NP[SEM=<cyril>] -> 'Cyril'\n",
    "- IV[SEM=<\\x.bark(x)>] -> 'barks'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2   The λ-Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞장에서 우리는 문서에서 우리가 원하는 단어를 선택할 때 단어의 특성 P의 집합으로 표현하는 것이 편리하다는 것을 보았다. \n",
    "\n",
    "\"어휘(vocabulary) V의 요소이면서 P라는 특성(property)을 가진 요소 w의 집합\"\n",
    "- {w | w ∈ V & P(w)} : mathematical set notation\n",
    "- λw. (V(w) ∧ P(w)) : **λ operator**\n",
    "\n",
    "λ is a binding operator, just as the first-order logic quantifiers are.  \n",
    "\n",
    "\n",
    "examples:\n",
    "\n",
    "- \t\t (walk(x) ∧ chew_gum(x)) : open formular\n",
    "\n",
    "- \t\t λx.(walk(x) ∧ chew_gum(x)) : binding the variable x with the λ operator\n",
    "\n",
    "- \t\t \\x.(walk(x) & chew_gum(x)) : NLTK representation \n",
    "\n",
    "\n",
    "Remember that \\ is a special character in Python strings. We could escape it (with another \\), or else use \"raw strings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\xXX escape (<ipython-input-6-3111eb3c386e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-3111eb3c386e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    expr = read_expr('\\x.(walk(x) & chew_gum(x))')\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\xXX escape\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "expr = read_expr('\\x.(walk(x) & chew_gum(x))')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LambdaExpression \\x.(walk(x) & chew_gum(x))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = read_expr(r'\\x.(walk(x) & chew_gum(x))') # using raw strings: string 앞에 'r'을 붙임\n",
    "expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "λ expression으로 결합된 결과는 **λ abstraction**이라 부른다. λ abstraction는 동사구(혹은 주어 없는 절)를 표현하기 좋은 방법이다. 동사구의 오른쪽에 붙여서 사용한다. \n",
    "- To walk and chew-gum is hard\n",
    "- hard(\\x.(walk(x) & chew_gum(x)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- \\x.(walk(x) & chew_gum(x)) (gerald)\n",
    "- \t(walk(gerald) & chew_gum(gerald))\n",
    "- (walk(x) & chew_gum(x))[gerald/x]\n",
    "\n",
    "**β-reduction.** : α[β/x] notation for the operation of replacing all free occurrences of x in α by the expression β. \n",
    "\n",
    "In order to carry of β-reduction of expressions in NLTK, we can call the simplify() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.(walk(x) & chew_gum(x))(gerald)\n",
      "(walk(gerald) & chew_gum(gerald))\n"
     ]
    }
   ],
   "source": [
    "expr = read_expr(r'\\x.(walk(x) & chew_gum(x))(gerald)')\n",
    "print(expr)\n",
    "print(expr.simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "λ abstract 두번 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\y.(dog(cyril) & own(y,cyril))\n",
      "(dog(cyril) & own(angus,cyril))\n"
     ]
    }
   ],
   "source": [
    "print(read_expr(r'\\x.\\y.(dog(x) & own(y, x))(cyril)').simplify())\n",
    "print(read_expr(r'\\x y.(dog(x) & own(y, x))(cyril, angus)').simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 수식을 표현하는데 쓰는 변수명(x,y,z,...)들은 의미가 있을까? 그렇지 않다. 변수의 이름은 임의로 설정할 수 있다. 즉 exists x.P(x) 와 exists y.P(y)는 동등하다. 이를 **α equivalents**, 혹은 **alphabetic variants**라 한다. 그리고 이 변수명을 변경하는 것(relabling)은 **α-conversion** 이라 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists x.P(x)\n",
      "exists z.P(z)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr1 = read_expr('exists x.P(x)')\n",
    "print(expr1)\n",
    "expr2 = expr1.alpha_convert(nltk.sem.Variable('z'))\n",
    "print(expr2)\n",
    "expr1 == expr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서 β-reduction 을 수행하면 이러한 relabling은 자동으로 수행된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\P.exists x.P(x))(\\y.see(y,x))\n",
      "exists z1.see(z1,x)\n"
     ]
    }
   ],
   "source": [
    "expr3 = read_expr('\\P.(exists x.P(x))(\\y.see(y, x))')\n",
    "print(expr3)\n",
    "print(expr3.simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3   Quantified NPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dog barks.\n",
    "\n",
    "exists x.(dog(x) & bark(x))\n",
    "\n",
    "\\P.exists x.(dog(x) & P(x))\n",
    "\n",
    "\\Q P.exists x.(Q(x) & P(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4   Transitive Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angus chases a dog.\n",
    "\n",
    "\\y.exists x.(dog(x) & chase(y, x))\n",
    "\n",
    "\\P.exists x.(dog(x) & P(x))(\\z.chase(y, z))\n",
    "\n",
    "X(\\z.chase(y, z))\n",
    "\n",
    "\\X y.X(\\x.chase(y, x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\X x.X(\\y.chase(x,y)))(\\P.exists x.(dog(x) & P(x)))\n",
      "\\x.exists z2.(dog(z2) & chase(x,z2))\n"
     ]
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "tvp = read_expr(r'\\X x.X(\\y.chase(x,y))')\n",
    "np = read_expr(r'(\\P.exists x.(dog(x) & P(x)))')\n",
    "vp = nltk.sem.ApplicationExpression(tvp, np)\n",
    "print(vp)\n",
    "print(vp.simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all z4.(dog(z4) -> exists z3.(bone(z3) & give(angus,z3,z4)))\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "parser = load_parser('grammars/book_grammars/simple-sem.fcfg', trace=0)\n",
    "sentence = 'Angus gives a bone to every dog'\n",
    "tokens = sentence.split()\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree.label()['SEM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<walk(irene)>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.P(irene)>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.P(irene)>] Irene))\n",
      "  (VP[NUM='sg', SEM=<\\x.walk(x)>]\n",
      "    (IV[NUM='sg', SEM=<\\x.walk(x)>, TNS='pres'] walks)))\n",
      "(S[SEM=<exists z5.(ankle(z5) & bite(cyril,z5))>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.P(cyril)>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.P(cyril)>] Cyril))\n",
      "  (VP[NUM='sg', SEM=<\\x.exists z5.(ankle(z5) & bite(x,z5))>]\n",
      "    (TV[NUM='sg', SEM=<\\X x.X(\\y.bite(x,y))>, TNS='pres'] bites)\n",
      "    (NP[NUM='sg', SEM=<\\Q.exists x.(ankle(x) & Q(x))>]\n",
      "      (Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>] an)\n",
      "      (Nom[NUM='sg', SEM=<\\x.ankle(x)>]\n",
      "        (N[NUM='sg', SEM=<\\x.ankle(x)>] ankle)))))\n"
     ]
    }
   ],
   "source": [
    "sents = ['Irene walks', 'Cyril bites an ankle']\n",
    "grammar_file = 'grammars/book_grammars/simple-sem.fcfg'\n",
    "\n",
    "for results in nltk.interpret_sents(sents, grammar_file):\n",
    "    for (synrep, semrep) in results:\n",
    "        print(synrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all z6.(boy(z6) -> see(cyril,z6))\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "v = \"\"\"\n",
    "bertie => b\n",
    "olive => o\n",
    "cyril => c\n",
    "boy => {b}\n",
    "girl => {o}\n",
    "dog => {c}\n",
    "walk => {o, c}\n",
    "see => {(b, o), (c, b), (o, c)}\n",
    "\"\"\"\n",
    "\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "g = nltk.Assignment(val.domain)\n",
    "m = nltk.Model(val.domain, val)\n",
    "sent = 'Cyril sees every boy'\n",
    "grammar_file = 'grammars/book_grammars/simple-sem.fcfg'\n",
    "\n",
    "results = nltk.evaluate_sents([sent], grammar_file, m, g)[0]\n",
    "for (syntree, semrep, value) in results:\n",
    "    print(semrep)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5   Quantifier Ambiguity Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 설명한 방법들의 한계는 scope ambiguity를 다루지 않는다는 점. 예를 들어, \n",
    "\n",
    "Every girl chases a dog. 이 문장은 a.로만 표현될 뿐 b.로는 표현되지 않는다. \n",
    "\n",
    "a.\t\tall x.(girl(x) -> exists y.(dog(y) & chase(x,y)))\n",
    "\n",
    "b.\t\texists y.(dog(y) & all x.(girl(x) -> chase(x,y)))\n",
    "\n",
    "<img src = \"images/scoping.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cooper storage**: a semantic representation is a pair consisting of a **core semantic representation** plus a list of **binding operators**.\n",
    "\n",
    "binding operators 는 'quantified NP'에서와 같은 semantic representation 으로,  core는  chase(x,y)로 생각하자.\n",
    "\n",
    "\\P.exists y.(dog(y) & P(y))(\\z2.chase(z1,z2))\n",
    "\n",
    "\\P.all x.(girl(x) -> P(x))(\\z1.exists x.(dog(x) & chase(z1,x)))\n",
    "\n",
    "binding operator list가 비었을땐, 문장의 논리적인 형태(conventional logical form)를 볼 수 있다. 이를 **S-Retrieval** 이라 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV[SEM=[core=<\\x.smile(x)>, store=(/)]] -> 'smiles'\n",
    "\n",
    "NP[SEM=[core=<@x>, store=(<bo(\\P.P(cyril),@x)>)]] -> 'Cyril'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5   Discourse Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **discourse** is a sequence of sentences. 많은 경우, 문장의 해석은 그것의 순서에 크게 의존함. 대표적으로 대명사들 (anaphoric pronouns, such as he, she and it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1   Discourse Representation Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.      Angus owns a dog. It bit Irene.\n",
    "\n",
    "b.\t\t∃x.(dog(x) ∧ own(Angus, x) ∧ bite(x, Irene))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2   Discourse Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
