{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300 \n",
    "from IPython.display import Image\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Classify Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 언어 데이터에서 분류를 위해 특징적인 피처들을 어떻게 알아낼 수 있는가? <br>\n",
    "2. 자동 언어 처리를 위해 필요한 언어 모델을 어떻게 만드는가? <br>\n",
    "3. 이러한 모델들을 통하여 우리가 언어에 대해 배울 수 있는 것은 무엇인가? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 지도 분류 (Supervised Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류란 주어진 인풋에 대하여 알맞은 'class label'을 선택하는 것 <br>\n",
    "- 이메일이 스팸인지 아닌지\n",
    "- 뉴스 기사의 주제가 무엇인지 \n",
    "- 단어의 뜻이 무엇으로 쓰였는지 (뜻이 여러 개인 경우)<br>\n",
    "분류기는 학습 코퍼스가 각각의 인풋에 대해 정확한 레이블을 가지고 있을 때 '지도'되었다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/supervised.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Gender Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류기를 만들 때 중요한 것은 어떤 인풋 피처들이 관련성이 높은지, 그리고 그 피처들을 어떻게 인코딩할것인지이다.\n",
    "# 예를 들면, a, e, i로 끝나는 이름들은 여성일 확률이 높고, k, o, r, s 등은 남성일 확률이 높다.\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]} # feature set: feature name: 'last_letter'\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "    [(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aamir',\n",
       " 'Aaron',\n",
       " 'Abbey',\n",
       " 'Abbie',\n",
       " 'Abbot',\n",
       " 'Abbott',\n",
       " 'Abby',\n",
       " 'Abdel',\n",
       " 'Abdul',\n",
       " 'Abdulkarim',\n",
       " 'Abdullah',\n",
       " 'Abe',\n",
       " 'Abel',\n",
       " 'Abelard',\n",
       " 'Abner',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Ace',\n",
       " 'Adair',\n",
       " 'Adam',\n",
       " 'Adams',\n",
       " 'Addie',\n",
       " 'Adger',\n",
       " 'Aditya',\n",
       " 'Adlai',\n",
       " 'Adnan',\n",
       " 'Adolf',\n",
       " 'Adolfo',\n",
       " 'Adolph',\n",
       " 'Adolphe',\n",
       " 'Adolpho',\n",
       " 'Adolphus',\n",
       " 'Adrian',\n",
       " 'Adrick',\n",
       " 'Adrien',\n",
       " 'Agamemnon',\n",
       " 'Aguinaldo',\n",
       " 'Aguste',\n",
       " 'Agustin',\n",
       " 'Aharon',\n",
       " 'Ahmad',\n",
       " 'Ahmed',\n",
       " 'Ahmet',\n",
       " 'Ajai',\n",
       " 'Ajay',\n",
       " 'Al',\n",
       " 'Alaa',\n",
       " 'Alain',\n",
       " 'Alan',\n",
       " 'Alasdair',\n",
       " 'Alastair',\n",
       " 'Albatros',\n",
       " 'Albert',\n",
       " 'Alberto',\n",
       " 'Albrecht',\n",
       " 'Alden',\n",
       " 'Aldis',\n",
       " 'Aldo',\n",
       " 'Aldric',\n",
       " 'Aldrich',\n",
       " 'Aldus',\n",
       " 'Aldwin',\n",
       " 'Alec',\n",
       " 'Aleck',\n",
       " 'Alejandro',\n",
       " 'Aleks',\n",
       " 'Aleksandrs',\n",
       " 'Alessandro',\n",
       " 'Alex',\n",
       " 'Alexander',\n",
       " 'Alexei',\n",
       " 'Alexis',\n",
       " 'Alf',\n",
       " 'Alfie',\n",
       " 'Alfonse',\n",
       " 'Alfonso',\n",
       " 'Alfonzo',\n",
       " 'Alford',\n",
       " 'Alfred',\n",
       " 'Alfredo',\n",
       " 'Algernon',\n",
       " 'Ali',\n",
       " 'Alic',\n",
       " 'Alister',\n",
       " 'Alix',\n",
       " 'Allah',\n",
       " 'Allan',\n",
       " 'Allen',\n",
       " 'Alley',\n",
       " 'Allie',\n",
       " 'Allin',\n",
       " 'Allyn',\n",
       " 'Alonso',\n",
       " 'Alonzo',\n",
       " 'Aloysius',\n",
       " 'Alphonse',\n",
       " 'Alphonso',\n",
       " 'Alston',\n",
       " 'Alton',\n",
       " 'Alvin',\n",
       " 'Alwin',\n",
       " 'Amadeus',\n",
       " 'Ambros',\n",
       " 'Ambrose',\n",
       " 'Ambrosi',\n",
       " 'Ambrosio',\n",
       " 'Ambrosius',\n",
       " 'Amery',\n",
       " 'Amory',\n",
       " 'Amos',\n",
       " 'Anatol',\n",
       " 'Anatole',\n",
       " 'Anatollo',\n",
       " 'Anatoly',\n",
       " 'Anders',\n",
       " 'Andie',\n",
       " 'Andonis',\n",
       " 'Andre',\n",
       " 'Andrea',\n",
       " 'Andreas',\n",
       " 'Andrej',\n",
       " 'Andres',\n",
       " 'Andrew',\n",
       " 'Andrey',\n",
       " 'Andri',\n",
       " 'Andros',\n",
       " 'Andrus',\n",
       " 'Andrzej',\n",
       " 'Andy',\n",
       " 'Angel',\n",
       " 'Angelico',\n",
       " 'Angelo',\n",
       " 'Angie',\n",
       " 'Angus',\n",
       " 'Ansel',\n",
       " 'Ansell',\n",
       " 'Anselm',\n",
       " 'Anson',\n",
       " 'Anthony',\n",
       " 'Antin',\n",
       " 'Antoine',\n",
       " 'Anton',\n",
       " 'Antone',\n",
       " 'Antoni',\n",
       " 'Antonin',\n",
       " 'Antonino',\n",
       " 'Antonio',\n",
       " 'Antonius',\n",
       " 'Antony',\n",
       " 'Anurag',\n",
       " 'Apollo',\n",
       " 'Apostolos',\n",
       " 'Aram',\n",
       " 'Archibald',\n",
       " 'Archibold',\n",
       " 'Archie',\n",
       " 'Archon',\n",
       " 'Archy',\n",
       " 'Arel',\n",
       " 'Ari',\n",
       " 'Arie',\n",
       " 'Ariel',\n",
       " 'Aristotle',\n",
       " 'Arlo',\n",
       " 'Armand',\n",
       " 'Armando',\n",
       " 'Armond',\n",
       " 'Armstrong',\n",
       " 'Arne',\n",
       " 'Arnie',\n",
       " 'Arnold',\n",
       " 'Arnoldo',\n",
       " 'Aron',\n",
       " 'Arron',\n",
       " 'Art',\n",
       " 'Arther',\n",
       " 'Arthur',\n",
       " 'Artie',\n",
       " 'Artur',\n",
       " 'Arturo',\n",
       " 'Arvie',\n",
       " 'Arvin',\n",
       " 'Arvind',\n",
       " 'Arvy',\n",
       " 'Ash',\n",
       " 'Ashby',\n",
       " 'Ashish',\n",
       " 'Ashley',\n",
       " 'Ashton',\n",
       " 'Aub',\n",
       " 'Aube',\n",
       " 'Aubert',\n",
       " 'Aubrey',\n",
       " 'Augie',\n",
       " 'August',\n",
       " 'Augustin',\n",
       " 'Augustine',\n",
       " 'Augusto',\n",
       " 'Augustus',\n",
       " 'Austen',\n",
       " 'Austin',\n",
       " 'Ave',\n",
       " 'Averell',\n",
       " 'Averil',\n",
       " 'Averill',\n",
       " 'Avery',\n",
       " 'Avi',\n",
       " 'Avraham',\n",
       " 'Avram',\n",
       " 'Avrom',\n",
       " 'Axel',\n",
       " 'Aylmer',\n",
       " 'Aziz',\n",
       " 'Bailey',\n",
       " 'Bailie',\n",
       " 'Baillie',\n",
       " 'Baily',\n",
       " 'Baird',\n",
       " 'Baldwin',\n",
       " 'Bancroft',\n",
       " 'Barbabas',\n",
       " 'Barclay',\n",
       " 'Bard',\n",
       " 'Barde',\n",
       " 'Barn',\n",
       " 'Barnabas',\n",
       " 'Barnabe',\n",
       " 'Barnaby',\n",
       " 'Barnard',\n",
       " 'Barnebas',\n",
       " 'Barnett',\n",
       " 'Barney',\n",
       " 'Barnie',\n",
       " 'Barny',\n",
       " 'Baron',\n",
       " 'Barr',\n",
       " 'Barret',\n",
       " 'Barrett',\n",
       " 'Barri',\n",
       " 'Barrie',\n",
       " 'Barris',\n",
       " 'Barron',\n",
       " 'Barry',\n",
       " 'Bart',\n",
       " 'Bartel',\n",
       " 'Barth',\n",
       " 'Barthel',\n",
       " 'Bartholemy',\n",
       " 'Bartholomeo',\n",
       " 'Bartholomeus',\n",
       " 'Bartholomew',\n",
       " 'Bartie',\n",
       " 'Bartlet',\n",
       " 'Bartlett',\n",
       " 'Bartolemo',\n",
       " 'Bartolomei',\n",
       " 'Bartolomeo',\n",
       " 'Barton',\n",
       " 'Barty',\n",
       " 'Bary',\n",
       " 'Basil',\n",
       " 'Batholomew',\n",
       " 'Baxter',\n",
       " 'Bay',\n",
       " 'Bayard',\n",
       " 'Beale',\n",
       " 'Bealle',\n",
       " 'Bear',\n",
       " 'Bearnard',\n",
       " 'Beau',\n",
       " 'Beaufort',\n",
       " 'Beauregard',\n",
       " 'Beck',\n",
       " 'Bela',\n",
       " 'Ben',\n",
       " 'Benedict',\n",
       " 'Bengt',\n",
       " 'Benito',\n",
       " 'Benjamen',\n",
       " 'Benjamin',\n",
       " 'Benji',\n",
       " 'Benjie',\n",
       " 'Benjy',\n",
       " 'Benn',\n",
       " 'Bennet',\n",
       " 'Bennett',\n",
       " 'Bennie',\n",
       " 'Benny',\n",
       " 'Benson',\n",
       " 'Bentley',\n",
       " 'Benton',\n",
       " 'Beowulf',\n",
       " 'Berchtold',\n",
       " 'Berk',\n",
       " 'Berke',\n",
       " 'Berkeley',\n",
       " 'Berkie',\n",
       " 'Berkley',\n",
       " 'Bernard',\n",
       " 'Bernardo',\n",
       " 'Bernd',\n",
       " 'Bernhard',\n",
       " 'Bernie',\n",
       " 'Bert',\n",
       " 'Bertie',\n",
       " 'Bertram',\n",
       " 'Bertrand',\n",
       " 'Bharat',\n",
       " 'Biff',\n",
       " 'Bill',\n",
       " 'Billie',\n",
       " 'Billy',\n",
       " 'Bing',\n",
       " 'Binky',\n",
       " 'Bishop',\n",
       " 'Bjorn',\n",
       " 'Bjorne',\n",
       " 'Blaine',\n",
       " 'Blair',\n",
       " 'Blake',\n",
       " 'Blare',\n",
       " 'Blayne',\n",
       " 'Bo',\n",
       " 'Bob',\n",
       " 'Bobbie',\n",
       " 'Bobby',\n",
       " 'Bogart',\n",
       " 'Bogdan',\n",
       " 'Boniface',\n",
       " 'Boris',\n",
       " 'Boyce',\n",
       " 'Boyd',\n",
       " 'Brad',\n",
       " 'Braden',\n",
       " 'Bradford',\n",
       " 'Bradley',\n",
       " 'Bradly',\n",
       " 'Brady',\n",
       " 'Brandon',\n",
       " 'Brandy',\n",
       " 'Brant',\n",
       " 'Brendan',\n",
       " 'Brent',\n",
       " 'Bret',\n",
       " 'Brett',\n",
       " 'Brewer',\n",
       " 'Brewster',\n",
       " 'Brian',\n",
       " 'Brice',\n",
       " 'Briggs',\n",
       " 'Brinkley',\n",
       " 'Britt',\n",
       " 'Brock',\n",
       " 'Broddie',\n",
       " 'Broddy',\n",
       " 'Broderic',\n",
       " 'Broderick',\n",
       " 'Brodie',\n",
       " 'Brody',\n",
       " 'Bronson',\n",
       " 'Brook',\n",
       " 'Brooke',\n",
       " 'Brooks',\n",
       " 'Bruce',\n",
       " 'Bruno',\n",
       " 'Bryan',\n",
       " 'Bryant',\n",
       " 'Bryce',\n",
       " 'Bryn',\n",
       " 'Bryon',\n",
       " 'Bubba',\n",
       " 'Buck',\n",
       " 'Bucky',\n",
       " 'Bud',\n",
       " 'Buddy',\n",
       " 'Burgess',\n",
       " 'Burke',\n",
       " 'Burl',\n",
       " 'Burnaby',\n",
       " 'Burt',\n",
       " 'Burton',\n",
       " 'Buster',\n",
       " 'Butch',\n",
       " 'Butler',\n",
       " 'Byram',\n",
       " 'Byron',\n",
       " 'Caesar',\n",
       " 'Cain',\n",
       " 'Cal',\n",
       " 'Caldwell',\n",
       " 'Caleb',\n",
       " 'Calhoun',\n",
       " 'Calvin',\n",
       " 'Cam',\n",
       " 'Cameron',\n",
       " 'Cammy',\n",
       " 'Carey',\n",
       " 'Carl',\n",
       " 'Carleigh',\n",
       " 'Carlie',\n",
       " 'Carlin',\n",
       " 'Carlo',\n",
       " 'Carlos',\n",
       " 'Carlton',\n",
       " 'Carlyle',\n",
       " 'Carmine',\n",
       " 'Carroll',\n",
       " 'Carson',\n",
       " 'Carsten',\n",
       " 'Carter',\n",
       " 'Cary',\n",
       " 'Caryl',\n",
       " 'Case',\n",
       " 'Casey',\n",
       " 'Caspar',\n",
       " 'Casper',\n",
       " 'Cass',\n",
       " 'Cat',\n",
       " 'Cecil',\n",
       " 'Cesar',\n",
       " 'Chad',\n",
       " 'Chadd',\n",
       " 'Chaddie',\n",
       " 'Chaddy',\n",
       " 'Chadwick',\n",
       " 'Chaim',\n",
       " 'Chalmers',\n",
       " 'Chan',\n",
       " 'Chance',\n",
       " 'Chancey',\n",
       " 'Chanderjit',\n",
       " 'Chandler',\n",
       " 'Chane',\n",
       " 'Chariot',\n",
       " 'Charles',\n",
       " 'Charleton',\n",
       " 'Charley',\n",
       " 'Charlie',\n",
       " 'Charlton',\n",
       " 'Chas',\n",
       " 'Chase',\n",
       " 'Chaunce',\n",
       " 'Chauncey',\n",
       " 'Che',\n",
       " 'Chelton',\n",
       " 'Chen',\n",
       " 'Chester',\n",
       " 'Cheston',\n",
       " 'Chet',\n",
       " 'Chev',\n",
       " 'Chevalier',\n",
       " 'Chevy',\n",
       " 'Chip',\n",
       " 'Chris',\n",
       " 'Chrissy',\n",
       " 'Christ',\n",
       " 'Christian',\n",
       " 'Christiano',\n",
       " 'Christie',\n",
       " 'Christof',\n",
       " 'Christofer',\n",
       " 'Christoph',\n",
       " 'Christophe',\n",
       " 'Christopher',\n",
       " 'Christorpher',\n",
       " 'Christos',\n",
       " 'Christy',\n",
       " 'Chrisy',\n",
       " 'Chuck',\n",
       " 'Churchill',\n",
       " 'Clair',\n",
       " 'Claire',\n",
       " 'Clancy',\n",
       " 'Clarance',\n",
       " 'Clare',\n",
       " 'Clarence',\n",
       " 'Clark',\n",
       " 'Clarke',\n",
       " 'Claude',\n",
       " 'Claudio',\n",
       " 'Claudius',\n",
       " 'Claus',\n",
       " 'Clay',\n",
       " 'Clayborn',\n",
       " 'Clayborne',\n",
       " 'Claybourne',\n",
       " 'Clayton',\n",
       " 'Cleland',\n",
       " 'Clem',\n",
       " 'Clemens',\n",
       " 'Clement',\n",
       " 'Clemente',\n",
       " 'Clemmie',\n",
       " 'Cletus',\n",
       " 'Cleveland',\n",
       " 'Cliff',\n",
       " 'Clifford',\n",
       " 'Clifton',\n",
       " 'Clint',\n",
       " 'Clinten',\n",
       " 'Clinton',\n",
       " 'Clive',\n",
       " 'Clyde',\n",
       " 'Cob',\n",
       " 'Cobb',\n",
       " 'Cobbie',\n",
       " 'Cobby',\n",
       " 'Cody',\n",
       " 'Colbert',\n",
       " 'Cole',\n",
       " 'Coleman',\n",
       " 'Colin',\n",
       " 'Collin',\n",
       " 'Collins',\n",
       " 'Conan',\n",
       " 'Connie',\n",
       " 'Connolly',\n",
       " 'Connor',\n",
       " 'Conrad',\n",
       " 'Conroy',\n",
       " 'Constantin',\n",
       " 'Constantine',\n",
       " 'Constantinos',\n",
       " 'Conway',\n",
       " 'Cooper',\n",
       " 'Corbin',\n",
       " 'Corby',\n",
       " 'Corey',\n",
       " 'Corky',\n",
       " 'Cornelius',\n",
       " 'Cornellis',\n",
       " 'Corrie',\n",
       " 'Cortese',\n",
       " 'Corwin',\n",
       " 'Cory',\n",
       " 'Cosmo',\n",
       " 'Costa',\n",
       " 'Courtney',\n",
       " 'Craig',\n",
       " 'Crawford',\n",
       " 'Creighton',\n",
       " 'Cris',\n",
       " 'Cristopher',\n",
       " 'Curt',\n",
       " 'Curtice',\n",
       " 'Curtis',\n",
       " 'Cy',\n",
       " 'Cyril',\n",
       " 'Cyrill',\n",
       " 'Cyrille',\n",
       " 'Cyrillus',\n",
       " 'Cyrus',\n",
       " 'Dabney',\n",
       " 'Daffy',\n",
       " 'Dale',\n",
       " 'Dallas',\n",
       " 'Dalton',\n",
       " 'Damian',\n",
       " 'Damien',\n",
       " 'Damon',\n",
       " 'Dan',\n",
       " 'Dana',\n",
       " 'Dane',\n",
       " 'Dani',\n",
       " 'Danie',\n",
       " 'Daniel',\n",
       " 'Dannie',\n",
       " 'Danny',\n",
       " 'Dante',\n",
       " 'Darby',\n",
       " 'Darcy',\n",
       " 'Daren',\n",
       " 'Darian',\n",
       " 'Darien',\n",
       " 'Darin',\n",
       " 'Dario',\n",
       " 'Darius',\n",
       " 'Darrel',\n",
       " 'Darrell',\n",
       " 'Darren',\n",
       " 'Darrick',\n",
       " 'Darrin',\n",
       " 'Darryl',\n",
       " 'Darth',\n",
       " 'Darwin',\n",
       " 'Daryl',\n",
       " 'Daryle',\n",
       " 'Dave',\n",
       " 'Davey',\n",
       " 'David',\n",
       " 'Davidde',\n",
       " 'Davide',\n",
       " 'Davidson',\n",
       " 'Davie',\n",
       " 'Davin',\n",
       " 'Davis',\n",
       " 'Davon',\n",
       " 'Davoud',\n",
       " 'Davy',\n",
       " 'Dawson',\n",
       " 'Dean',\n",
       " 'Deane',\n",
       " 'Del',\n",
       " 'Delbert',\n",
       " 'Dell',\n",
       " 'Delmar',\n",
       " 'Demetre',\n",
       " 'Demetri',\n",
       " 'Demetris',\n",
       " 'Demetrius',\n",
       " 'Demosthenis',\n",
       " 'Denis',\n",
       " 'Dennie',\n",
       " 'Dennis',\n",
       " 'Denny',\n",
       " 'Derby',\n",
       " 'Derek',\n",
       " 'Derick',\n",
       " 'Derk',\n",
       " 'Derrek',\n",
       " 'Derrick',\n",
       " 'Derrin',\n",
       " 'Derrol',\n",
       " 'Derron',\n",
       " 'Deryl',\n",
       " 'Desmond',\n",
       " 'Desmund',\n",
       " 'Devin',\n",
       " 'Devon',\n",
       " 'Dewey',\n",
       " 'Dewitt',\n",
       " 'Dexter',\n",
       " 'Dick',\n",
       " 'Dickey',\n",
       " 'Dickie',\n",
       " 'Diego',\n",
       " 'Dieter',\n",
       " 'Dietrich',\n",
       " 'Dillon',\n",
       " 'Dimitri',\n",
       " 'Dimitrios',\n",
       " 'Dimitris',\n",
       " 'Dimitrou',\n",
       " 'Dimitry',\n",
       " 'Dino',\n",
       " 'Dion',\n",
       " 'Dionis',\n",
       " 'Dionysus',\n",
       " 'Dirk',\n",
       " 'Dmitri',\n",
       " 'Dom',\n",
       " 'Domenic',\n",
       " 'Domenico',\n",
       " 'Dominic',\n",
       " 'Dominick',\n",
       " 'Dominique',\n",
       " 'Don',\n",
       " 'Donal',\n",
       " 'Donald',\n",
       " 'Donn',\n",
       " 'Donnie',\n",
       " 'Donny',\n",
       " 'Donovan',\n",
       " 'Dorian',\n",
       " 'Dory',\n",
       " 'Doug',\n",
       " 'Douggie',\n",
       " 'Dougie',\n",
       " 'Douglas',\n",
       " 'Douglass',\n",
       " 'Douglis',\n",
       " 'Dov',\n",
       " 'Doyle',\n",
       " 'Drake',\n",
       " 'Drew',\n",
       " 'Dru',\n",
       " 'Dryke',\n",
       " 'Duane',\n",
       " 'Dudley',\n",
       " 'Duffie',\n",
       " 'Duffy',\n",
       " 'Dugan',\n",
       " 'Duke',\n",
       " 'Dunc',\n",
       " 'Duncan',\n",
       " 'Dunstan',\n",
       " 'Durand',\n",
       " 'Durant',\n",
       " 'Durante',\n",
       " 'Durward',\n",
       " 'Dustin',\n",
       " 'Dwain',\n",
       " 'Dwaine',\n",
       " 'Dwane',\n",
       " 'Dwayne',\n",
       " 'Dwight',\n",
       " 'Dylan',\n",
       " 'Dyson',\n",
       " 'Earl',\n",
       " 'Earle',\n",
       " 'Easton',\n",
       " 'Eben',\n",
       " 'Ebeneser',\n",
       " 'Ebenezer',\n",
       " 'Eberhard',\n",
       " 'Ed',\n",
       " 'Eddie',\n",
       " 'Eddy',\n",
       " 'Edgar',\n",
       " 'Edgardo',\n",
       " 'Edie',\n",
       " 'Edmond',\n",
       " 'Edmund',\n",
       " 'Edouard',\n",
       " 'Edsel',\n",
       " 'Eduard',\n",
       " 'Eduardo',\n",
       " 'Edward',\n",
       " 'Edwin',\n",
       " 'Efram',\n",
       " 'Egbert',\n",
       " 'Ehud',\n",
       " 'Elbert',\n",
       " 'Elden',\n",
       " 'Eldon',\n",
       " 'Eli',\n",
       " 'Elias',\n",
       " 'Elihu',\n",
       " 'Elijah',\n",
       " 'Eliot',\n",
       " 'Eliott',\n",
       " 'Elisha',\n",
       " 'Elliot',\n",
       " 'Elliott',\n",
       " 'Ellis',\n",
       " 'Ellsworth',\n",
       " 'Ellwood',\n",
       " 'Elmer',\n",
       " 'Elmore',\n",
       " 'Elnar',\n",
       " 'Elric',\n",
       " 'Elroy',\n",
       " 'Elton',\n",
       " 'Elvin',\n",
       " 'Elvis',\n",
       " 'Elwin',\n",
       " 'Elwood',\n",
       " 'Elwyn',\n",
       " 'Ely',\n",
       " 'Emanuel',\n",
       " 'Emerson',\n",
       " 'Emery',\n",
       " 'Emil',\n",
       " 'Emile',\n",
       " 'Emilio',\n",
       " 'Emmanuel',\n",
       " 'Emmery',\n",
       " 'Emmet',\n",
       " 'Emmett',\n",
       " 'Emmit',\n",
       " 'Emmott',\n",
       " 'Emmy',\n",
       " 'Emory',\n",
       " 'Ender',\n",
       " 'Engelbart',\n",
       " 'Engelbert',\n",
       " 'Englebart',\n",
       " 'Englebert',\n",
       " 'Enoch',\n",
       " 'Enrico',\n",
       " 'Enrique',\n",
       " 'Ephraim',\n",
       " 'Ephram',\n",
       " 'Ephrayim',\n",
       " 'Ephrem',\n",
       " 'Er',\n",
       " 'Erasmus',\n",
       " 'Erastus',\n",
       " 'Erek',\n",
       " 'Erhard',\n",
       " 'Erhart',\n",
       " 'Eric',\n",
       " 'Erich',\n",
       " 'Erick',\n",
       " 'Erik',\n",
       " 'Erin',\n",
       " 'Erl',\n",
       " 'Ernest',\n",
       " 'Ernesto',\n",
       " 'Ernie',\n",
       " 'Ernst',\n",
       " 'Erny',\n",
       " 'Errol',\n",
       " 'Ervin',\n",
       " 'Erwin',\n",
       " 'Esau',\n",
       " 'Esme',\n",
       " 'Esteban',\n",
       " 'Ethan',\n",
       " 'Ethelbert',\n",
       " 'Ethelred',\n",
       " 'Etienne',\n",
       " 'Euclid',\n",
       " 'Eugen',\n",
       " 'Eugene',\n",
       " 'Eustace',\n",
       " 'Ev',\n",
       " 'Evan',\n",
       " 'Evelyn',\n",
       " 'Everard',\n",
       " 'Everett',\n",
       " 'Ewan',\n",
       " 'Ewart',\n",
       " 'Ez',\n",
       " 'Ezechiel',\n",
       " 'Ezekiel',\n",
       " 'Ezra',\n",
       " 'Fabian',\n",
       " 'Fabio',\n",
       " 'Fairfax',\n",
       " 'Farley',\n",
       " 'Fazeel',\n",
       " 'Federico',\n",
       " 'Felice',\n",
       " 'Felicio',\n",
       " 'Felipe',\n",
       " 'Felix',\n",
       " 'Ferd',\n",
       " 'Ferdie',\n",
       " 'Ferdinand',\n",
       " 'Ferdy',\n",
       " 'Fergus',\n",
       " 'Ferguson',\n",
       " 'Ferinand',\n",
       " 'Fernando',\n",
       " 'Fidel',\n",
       " 'Filbert',\n",
       " 'Filip',\n",
       " 'Filipe',\n",
       " 'Filmore',\n",
       " 'Finley',\n",
       " 'Finn',\n",
       " 'Fitz',\n",
       " 'Fitzgerald',\n",
       " 'Flem',\n",
       " 'Fleming',\n",
       " 'Flemming',\n",
       " 'Fletch',\n",
       " 'Fletcher',\n",
       " 'Flin',\n",
       " 'Flinn',\n",
       " 'Flint',\n",
       " 'Flipper',\n",
       " 'Florian',\n",
       " 'Floyd',\n",
       " 'Flynn',\n",
       " 'Fons',\n",
       " 'Fonsie',\n",
       " 'Fonz',\n",
       " 'Fonzie',\n",
       " 'Forbes',\n",
       " 'Ford',\n",
       " 'Forest',\n",
       " 'Forester',\n",
       " 'Forrest',\n",
       " 'Forrester',\n",
       " 'Forster',\n",
       " 'Foster',\n",
       " 'Fowler',\n",
       " 'Fox',\n",
       " 'Fran',\n",
       " 'Francesco',\n",
       " 'Francis',\n",
       " 'Francisco',\n",
       " 'Francois',\n",
       " 'Frank',\n",
       " 'Frankie',\n",
       " 'Franklin',\n",
       " 'Franklyn',\n",
       " 'Franky',\n",
       " 'Frans',\n",
       " 'Franz',\n",
       " 'Fraser',\n",
       " 'Frazier',\n",
       " 'Fred',\n",
       " 'Freddie',\n",
       " 'Freddy',\n",
       " 'Frederic',\n",
       " 'Frederich',\n",
       " 'Frederick',\n",
       " 'Frederico',\n",
       " 'Frederik',\n",
       " 'Fredric',\n",
       " 'Fredrick',\n",
       " 'Freeman',\n",
       " 'Freemon',\n",
       " 'Fremont',\n",
       " 'French',\n",
       " 'Friedric',\n",
       " 'Friedrich',\n",
       " 'Friedrick',\n",
       " 'Fritz',\n",
       " 'Fulton',\n",
       " 'Fyodor',\n",
       " 'Gabe',\n",
       " 'Gabriel',\n",
       " 'Gabriele',\n",
       " 'Gabriell',\n",
       " 'Gabriello',\n",
       " 'Gail',\n",
       " 'Gale',\n",
       " 'Galen',\n",
       " 'Gallagher',\n",
       " 'Gamaliel',\n",
       " 'Garcia',\n",
       " 'Garcon',\n",
       " 'Gardener',\n",
       " 'Gardiner',\n",
       " 'Gardner',\n",
       " 'Garey',\n",
       " 'Garfield',\n",
       " 'Garfinkel',\n",
       " 'Garold',\n",
       " 'Garp',\n",
       " 'Garret',\n",
       " 'Garrett',\n",
       " 'Garrot',\n",
       " 'Garrott',\n",
       " 'Garry',\n",
       " 'Garth',\n",
       " 'Garv',\n",
       " 'Garvey',\n",
       " 'Garvin',\n",
       " 'Garvy',\n",
       " 'Garwin',\n",
       " 'Garwood',\n",
       " 'Gary',\n",
       " 'Gaspar',\n",
       " 'Gasper',\n",
       " 'Gaston',\n",
       " 'Gav',\n",
       " 'Gaven',\n",
       " 'Gavin',\n",
       " 'Gavriel',\n",
       " 'Gay',\n",
       " 'Gayle',\n",
       " 'Gearard',\n",
       " 'Gene',\n",
       " 'Geo',\n",
       " 'Geof',\n",
       " 'Geoff',\n",
       " 'Geoffrey',\n",
       " 'Geoffry',\n",
       " 'Georg',\n",
       " 'George',\n",
       " 'Georges',\n",
       " 'Georgia',\n",
       " 'Georgie',\n",
       " 'Georgy',\n",
       " 'Gerald',\n",
       " 'Geraldo',\n",
       " 'Gerard',\n",
       " 'Gere',\n",
       " 'Gerhard',\n",
       " 'Gerhardt',\n",
       " 'Geri',\n",
       " 'Germaine',\n",
       " 'Gerold',\n",
       " 'Gerome',\n",
       " 'Gerrard',\n",
       " 'Gerri',\n",
       " 'Gerrit',\n",
       " 'Gerry',\n",
       " 'Gershom',\n",
       " 'Gershon',\n",
       " 'Giacomo',\n",
       " 'Gian',\n",
       " 'Giancarlo',\n",
       " 'Giavani',\n",
       " 'Gibb',\n",
       " 'Gideon',\n",
       " 'Giff',\n",
       " 'Giffard',\n",
       " 'Giffer',\n",
       " 'Giffie',\n",
       " 'Gifford',\n",
       " 'Giffy',\n",
       " 'Gil',\n",
       " 'Gilbert',\n",
       " 'Gilberto',\n",
       " 'Gilburt',\n",
       " 'Giles',\n",
       " 'Gill',\n",
       " 'Gilles',\n",
       " 'Ginger',\n",
       " 'Gino',\n",
       " 'Giordano',\n",
       " 'Giorgi',\n",
       " 'Giorgio',\n",
       " 'Giovanne',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words('male.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 피처셋 (각 이름의 마지막 글자) 만들기\n",
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 나누자\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 분류기를 만들자\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예를 들어보자\n",
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Trinity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    }
   ],
   "source": [
    "# 우리가 만든 분류기 평가\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     38.6 : 1.0\n",
      "             last_letter = 'k'              male : female =     33.0 : 1.0\n",
      "             last_letter = 'v'              male : female =     18.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 무슨 피처가 제일 중요했나?\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 메모리를 너무 많이 차지하니, 리스트로 저장하되 메모리는 차지하지 않도록 하자\n",
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Choosing the Right Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "적절한 피처를 찾는 일은 매우 중요하다 (당연) 보통 \"kitchen sink\" 방법을 사용한다 -- 생각해낼 수 있는 모든 피처를 찾은 다음 어떤 피처가 도움이 되는지 좁혀 나가는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count(a)': 0,\n",
       " 'count(b)': 0,\n",
       " 'count(c)': 0,\n",
       " 'count(d)': 0,\n",
       " 'count(e)': 0,\n",
       " 'count(f)': 0,\n",
       " 'count(g)': 0,\n",
       " 'count(h)': 1,\n",
       " 'count(i)': 0,\n",
       " 'count(j)': 1,\n",
       " 'count(k)': 0,\n",
       " 'count(l)': 0,\n",
       " 'count(m)': 0,\n",
       " 'count(n)': 1,\n",
       " 'count(o)': 1,\n",
       " 'count(p)': 0,\n",
       " 'count(q)': 0,\n",
       " 'count(r)': 0,\n",
       " 'count(s)': 0,\n",
       " 'count(t)': 0,\n",
       " 'count(u)': 0,\n",
       " 'count(v)': 0,\n",
       " 'count(w)': 0,\n",
       " 'count(x)': 0,\n",
       " 'count(y)': 0,\n",
       " 'count(z)': 0,\n",
       " 'first_letter': 'j',\n",
       " 'has(a)': False,\n",
       " 'has(b)': False,\n",
       " 'has(c)': False,\n",
       " 'has(d)': False,\n",
       " 'has(e)': False,\n",
       " 'has(f)': False,\n",
       " 'has(g)': False,\n",
       " 'has(h)': True,\n",
       " 'has(i)': False,\n",
       " 'has(j)': True,\n",
       " 'has(k)': False,\n",
       " 'has(l)': False,\n",
       " 'has(m)': False,\n",
       " 'has(n)': True,\n",
       " 'has(o)': True,\n",
       " 'has(p)': False,\n",
       " 'has(q)': False,\n",
       " 'has(r)': False,\n",
       " 'has(s)': False,\n",
       " 'has(t)': False,\n",
       " 'has(u)': False,\n",
       " 'has(v)': False,\n",
       " 'has(w)': False,\n",
       " 'has(x)': False,\n",
       " 'has(y)': False,\n",
       " 'has(z)': False,\n",
       " 'last_letter': 'n'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overfitting을 주의해야 한다 (특히 학습 데이터가 적을 때)\n",
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# error analysis를 통해 피처를 줄여 갈 수 있다\n",
    "# development set = training set + dev-test set\n",
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/test_train.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Agnes                         \n",
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Allyson                       \n",
      "correct=female   guess=male     name=Ann                           \n",
      "correct=female   guess=male     name=Arleen                        \n",
      "correct=female   guess=male     name=Avrit                         \n",
      "correct=female   guess=male     name=Bab                           \n",
      "correct=female   guess=male     name=Beitris                       \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Brigid                        \n",
      "correct=female   guess=male     name=Candis                        \n",
      "correct=female   guess=male     name=Carlynn                       \n",
      "correct=female   guess=male     name=Carolan                       \n",
      "correct=female   guess=male     name=Caryn                         \n",
      "correct=female   guess=male     name=Charin                        \n",
      "correct=female   guess=male     name=Charlean                      \n",
      "correct=female   guess=male     name=Charmion                      \n",
      "correct=female   guess=male     name=Chloris                       \n",
      "correct=female   guess=male     name=Christean                     \n",
      "correct=female   guess=male     name=Clo                           \n",
      "correct=female   guess=male     name=Coriss                        \n",
      "correct=female   guess=male     name=Damaris                       \n",
      "correct=female   guess=male     name=Doreen                        \n",
      "correct=female   guess=male     name=Dorian                        \n",
      "correct=female   guess=male     name=Dorit                         \n",
      "correct=female   guess=male     name=Dyan                          \n",
      "correct=female   guess=male     name=Elizabet                      \n",
      "correct=female   guess=male     name=Ellynn                        \n",
      "correct=female   guess=male     name=Fanchon                       \n",
      "correct=female   guess=male     name=Faun                          \n",
      "correct=female   guess=male     name=Garnet                        \n",
      "correct=female   guess=male     name=Glynnis                       \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hildegaard                    \n",
      "correct=female   guess=male     name=Ingaborg                      \n",
      "correct=female   guess=male     name=Jaclin                        \n",
      "correct=female   guess=male     name=Janean                        \n",
      "correct=female   guess=male     name=Jeniffer                      \n",
      "correct=female   guess=male     name=Jo                            \n",
      "correct=female   guess=male     name=Jolynn                        \n",
      "correct=female   guess=male     name=Jordan                        \n",
      "correct=female   guess=male     name=Karalynn                      \n",
      "correct=female   guess=male     name=Kass                          \n",
      "correct=female   guess=male     name=Kim                           \n",
      "correct=female   guess=male     name=Kipp                          \n",
      "correct=female   guess=male     name=Kristen                       \n",
      "correct=female   guess=male     name=Kristien                      \n",
      "correct=female   guess=male     name=Kyrstin                       \n",
      "correct=female   guess=male     name=Lamb                          \n",
      "correct=female   guess=male     name=Leanor                        \n",
      "correct=female   guess=male     name=Lilas                         \n",
      "correct=female   guess=male     name=Linnet                        \n",
      "correct=female   guess=male     name=Lois                          \n",
      "correct=female   guess=male     name=Madelon                       \n",
      "correct=female   guess=male     name=Madlin                        \n",
      "correct=female   guess=male     name=Mairead                       \n",
      "correct=female   guess=male     name=Margeaux                      \n",
      "correct=female   guess=male     name=Maris                         \n",
      "correct=female   guess=male     name=Maryellen                     \n",
      "correct=female   guess=male     name=Marylin                       \n",
      "correct=female   guess=male     name=Max                           \n",
      "correct=female   guess=male     name=Megan                         \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Miran                         \n",
      "correct=female   guess=male     name=Nadeen                        \n",
      "correct=female   guess=male     name=Nariko                        \n",
      "correct=female   guess=male     name=Nitin                         \n",
      "correct=female   guess=male     name=Olwen                         \n",
      "correct=female   guess=male     name=Regan                         \n",
      "correct=female   guess=male     name=Rhianon                       \n",
      "correct=female   guess=male     name=Robinet                       \n",
      "correct=female   guess=male     name=Rosamund                      \n",
      "correct=female   guess=male     name=Row                           \n",
      "correct=female   guess=male     name=Shaun                         \n",
      "correct=female   guess=male     name=Sher                          \n",
      "correct=female   guess=male     name=Siobhan                       \n",
      "correct=female   guess=male     name=Storm                         \n",
      "correct=female   guess=male     name=Taryn                         \n",
      "correct=female   guess=male     name=Thomasin                      \n",
      "correct=female   guess=male     name=Tiff                          \n",
      "correct=female   guess=male     name=Trix                          \n",
      "correct=female   guess=male     name=Veradis                       \n",
      "correct=female   guess=male     name=Vivien                        \n",
      "correct=female   guess=male     name=Viviyan                       \n",
      "correct=female   guess=male     name=Willow                        \n",
      "correct=male     guess=female   name=Abdullah                      \n",
      "correct=male     guess=female   name=Adlai                         \n",
      "correct=male     guess=female   name=Ajay                          \n",
      "correct=male     guess=female   name=Andie                         \n",
      "correct=male     guess=female   name=Andrea                        \n",
      "correct=male     guess=female   name=Arel                          \n",
      "correct=male     guess=female   name=Ariel                         \n",
      "correct=male     guess=female   name=Artie                         \n",
      "correct=male     guess=female   name=Benjy                         \n",
      "correct=male     guess=female   name=Bentley                       \n",
      "correct=male     guess=female   name=Bjorne                        \n",
      "correct=male     guess=female   name=Boniface                      \n",
      "correct=male     guess=female   name=Brice                         \n",
      "correct=male     guess=female   name=Broddie                       \n",
      "correct=male     guess=female   name=Burl                          \n",
      "correct=male     guess=female   name=Cal                           \n",
      "correct=male     guess=female   name=Carleigh                      \n",
      "correct=male     guess=female   name=Cary                          \n",
      "correct=male     guess=female   name=Chevy                         \n",
      "correct=male     guess=female   name=Christie                      \n",
      "correct=male     guess=female   name=Clarke                        \n",
      "correct=male     guess=female   name=Clemente                      \n",
      "correct=male     guess=female   name=Cobby                         \n",
      "correct=male     guess=female   name=Daniel                        \n",
      "correct=male     guess=female   name=Darrell                       \n",
      "correct=male     guess=female   name=Darryl                        \n",
      "correct=male     guess=female   name=Darth                         \n",
      "correct=male     guess=female   name=Daryl                         \n",
      "correct=male     guess=female   name=Dimitri                       \n",
      "correct=male     guess=female   name=Dimitry                       \n",
      "correct=male     guess=female   name=Duane                         \n",
      "correct=male     guess=female   name=Eli                           \n",
      "correct=male     guess=female   name=Elisha                        \n",
      "correct=male     guess=female   name=Elmore                        \n",
      "correct=male     guess=female   name=Emery                         \n",
      "correct=male     guess=female   name=Errol                         \n",
      "correct=male     guess=female   name=Fazeel                        \n",
      "correct=male     guess=female   name=Fidel                         \n",
      "correct=male     guess=female   name=Filipe                        \n",
      "correct=male     guess=female   name=Fonzie                        \n",
      "correct=male     guess=female   name=Friedrich                     \n",
      "correct=male     guess=female   name=Gabriele                      \n",
      "correct=male     guess=female   name=Garfinkel                     \n",
      "correct=male     guess=female   name=Gene                          \n",
      "correct=male     guess=female   name=Geoffrey                      \n",
      "correct=male     guess=female   name=Geoffry                       \n",
      "correct=male     guess=female   name=Gerry                         \n",
      "correct=male     guess=female   name=Graehme                       \n",
      "correct=male     guess=female   name=Granville                     \n",
      "correct=male     guess=female   name=Hall                          \n",
      "correct=male     guess=female   name=Hannibal                      \n",
      "correct=male     guess=female   name=Hansel                        \n",
      "correct=male     guess=female   name=Haskel                        \n",
      "correct=male     guess=female   name=Herbie                        \n",
      "correct=male     guess=female   name=Hiralal                       \n",
      "correct=male     guess=female   name=Ismail                        \n",
      "correct=male     guess=female   name=Jackie                        \n",
      "correct=male     guess=female   name=Jay                           \n",
      "correct=male     guess=female   name=Jereme                        \n",
      "correct=male     guess=female   name=Jeremy                        \n",
      "correct=male     guess=female   name=Jerome                        \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Jody                          \n",
      "correct=male     guess=female   name=Johnny                        \n",
      "correct=male     guess=female   name=Josh                          \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Kendal                        \n",
      "correct=male     guess=female   name=Kennedy                       \n",
      "correct=male     guess=female   name=Laurie                        \n",
      "correct=male     guess=female   name=Lindy                         \n",
      "correct=male     guess=female   name=Mackenzie                     \n",
      "correct=male     guess=female   name=Marshall                      \n",
      "correct=male     guess=female   name=Martie                        \n",
      "correct=male     guess=female   name=Marty                         \n",
      "correct=male     guess=female   name=Marve                         \n",
      "correct=male     guess=female   name=Matty                         \n",
      "correct=male     guess=female   name=Merry                         \n",
      "correct=male     guess=female   name=Michel                        \n",
      "correct=male     guess=female   name=Michele                       \n",
      "correct=male     guess=female   name=Mikey                         \n",
      "correct=male     guess=female   name=Mitchell                      \n",
      "correct=male     guess=female   name=Monty                         \n",
      "correct=male     guess=female   name=Mordecai                      \n",
      "correct=male     guess=female   name=Morly                         \n",
      "correct=male     guess=female   name=Morty                         \n",
      "correct=male     guess=female   name=Munroe                        \n",
      "correct=male     guess=female   name=Neal                          \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Nikki                         \n",
      "correct=male     guess=female   name=Nikolai                       \n",
      "correct=male     guess=female   name=Noble                         \n",
      "correct=male     guess=female   name=Obie                          \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Oral                          \n",
      "correct=male     guess=female   name=Paddie                        \n",
      "correct=male     guess=female   name=Parrnell                      \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Pepe                          \n",
      "correct=male     guess=female   name=Perceval                      \n",
      "correct=male     guess=female   name=Percival                      \n",
      "correct=male     guess=female   name=Piggy                         \n",
      "correct=male     guess=female   name=Rafe                          \n",
      "correct=male     guess=female   name=Ramsay                        \n",
      "correct=male     guess=female   name=Randell                       \n",
      "correct=male     guess=female   name=Reggie                        \n",
      "correct=male     guess=female   name=Rene                          \n",
      "correct=male     guess=female   name=Richy                         \n",
      "correct=male     guess=female   name=Rickey                        \n",
      "correct=male     guess=female   name=Rickie                        \n",
      "correct=male     guess=female   name=Rolfe                         \n",
      "correct=male     guess=female   name=Ruddie                        \n",
      "correct=male     guess=female   name=Rudie                         \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Sidnee                        \n",
      "correct=male     guess=female   name=Siffre                        \n",
      "correct=male     guess=female   name=Sinclare                      \n",
      "correct=male     guess=female   name=Sky                           \n",
      "correct=male     guess=female   name=Sol                           \n",
      "correct=male     guess=female   name=Stevie                        \n",
      "correct=male     guess=female   name=Stinky                        \n",
      "correct=male     guess=female   name=Terrell                       \n",
      "correct=male     guess=female   name=Thornie                       \n",
      "correct=male     guess=female   name=Toddy                         \n",
      "correct=male     guess=female   name=Torre                         \n",
      "correct=male     guess=female   name=Tracie                        \n",
      "correct=male     guess=female   name=Tremayne                      \n",
      "correct=male     guess=female   name=Vail                          \n",
      "correct=male     guess=female   name=Vinnie                        \n",
      "correct=male     guess=female   name=Walsh                         \n",
      "correct=male     guess=female   name=Wash                          \n",
      "correct=male     guess=female   name=Way                           \n",
      "correct=male     guess=female   name=Wendell                       \n",
      "correct=male     guess=female   name=Woody                         \n",
      "correct=male     guess=female   name=Yankee                        \n",
      "correct=male     guess=female   name=Yigal                         \n",
      "correct=male     guess=female   name=Zachariah                     \n",
      "correct=male     guess=female   name=Zippy                         \n",
      "correct=male     guess=female   name=Zollie                        \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:8} name={:30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 성별을 맞추는 데 한 글자 이상의 글자들이 필요할 수 있다는 것을 확인하였다\n",
    "# 이제 두 글자 접미사를 사용하여 성별을 구분해 보자\n",
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "           'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, devtest_set)) # 정확도가 조금 증가함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1과에서 레이블 된 코퍼스를 본 것처럼, 새로운 문서가 들어왔을 때 태그를 새로 달아줄 수 있는 분류기를 만들 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문서에서 피처 추출 - 문서가 특정 단어를 포함하고 있는지 아닌지를 판별 \n",
    "# 전체 코퍼스에서 가장 빈번하게 등장하는 단어 2000개 \n",
    "# 이 2000개의 단어들이 각 문서에 있는지 확인\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(plot)': True, 'contains(:)': True, 'contains(two)': True, 'contains(teen)': False, 'contains(couples)': False, 'contains(go)': False, 'contains(to)': True, 'contains(a)': True, 'contains(church)': False, 'contains(party)': False, 'contains(,)': True, 'contains(drink)': False, 'contains(and)': True, 'contains(then)': True, 'contains(drive)': False, 'contains(.)': True, 'contains(they)': True, 'contains(get)': True, 'contains(into)': True, 'contains(an)': True, 'contains(accident)': False, 'contains(one)': True, 'contains(of)': True, 'contains(the)': True, 'contains(guys)': False, 'contains(dies)': False, 'contains(but)': True, 'contains(his)': True, 'contains(girlfriend)': True, 'contains(continues)': False, 'contains(see)': False, 'contains(him)': True, 'contains(in)': True, 'contains(her)': False, 'contains(life)': False, 'contains(has)': True, 'contains(nightmares)': False, 'contains(what)': True, \"contains(')\": True, 'contains(s)': True, 'contains(deal)': False, 'contains(?)': False, 'contains(watch)': True, 'contains(movie)': True, 'contains(\")': True, 'contains(sorta)': False, 'contains(find)': False, 'contains(out)': True, 'contains(critique)': False, 'contains(mind)': False, 'contains(-)': True, 'contains(fuck)': False, 'contains(for)': True, 'contains(generation)': False, 'contains(that)': True, 'contains(touches)': False, 'contains(on)': True, 'contains(very)': True, 'contains(cool)': False, 'contains(idea)': True, 'contains(presents)': False, 'contains(it)': True, 'contains(bad)': False, 'contains(package)': False, 'contains(which)': True, 'contains(is)': True, 'contains(makes)': False, 'contains(this)': True, 'contains(review)': False, 'contains(even)': False, 'contains(harder)': False, 'contains(write)': False, 'contains(since)': False, 'contains(i)': False, 'contains(generally)': False, 'contains(applaud)': False, 'contains(films)': False, 'contains(attempt)': False, 'contains(break)': False, 'contains(mold)': False, 'contains(mess)': False, 'contains(with)': True, 'contains(your)': False, 'contains(head)': False, 'contains(such)': False, 'contains(()': True, 'contains(lost)': False, 'contains(highway)': False, 'contains(&)': False, 'contains(memento)': False, 'contains())': True, 'contains(there)': True, 'contains(are)': True, 'contains(good)': False, 'contains(ways)': False, 'contains(making)': True, 'contains(all)': True, 'contains(types)': False, 'contains(these)': False, 'contains(folks)': False, 'contains(just)': True, 'contains(didn)': False, 'contains(t)': False, 'contains(snag)': False, 'contains(correctly)': False, 'contains(seem)': False, 'contains(have)': True, 'contains(taken)': False, 'contains(pretty)': False, 'contains(neat)': False, 'contains(concept)': False, 'contains(executed)': False, 'contains(terribly)': False, 'contains(so)': False, 'contains(problems)': True, 'contains(well)': True, 'contains(its)': False, 'contains(main)': False, 'contains(problem)': False, 'contains(simply)': False, 'contains(too)': False, 'contains(jumbled)': False, 'contains(starts)': False, 'contains(off)': False, 'contains(normal)': False, 'contains(downshifts)': False, 'contains(fantasy)': False, 'contains(world)': True, 'contains(you)': True, 'contains(as)': True, 'contains(audience)': False, 'contains(member)': False, 'contains(no)': False, 'contains(going)': False, 'contains(dreams)': False, 'contains(characters)': False, 'contains(coming)': False, 'contains(back)': False, 'contains(from)': True, 'contains(dead)': False, 'contains(others)': True, 'contains(who)': True, 'contains(look)': True, 'contains(like)': True, 'contains(strange)': False, 'contains(apparitions)': False, 'contains(disappearances)': False, 'contains(looooot)': False, 'contains(chase)': True, 'contains(scenes)': False, 'contains(tons)': False, 'contains(weird)': False, 'contains(things)': True, 'contains(happen)': False, 'contains(most)': True, 'contains(not)': True, 'contains(explained)': False, 'contains(now)': False, 'contains(personally)': False, 'contains(don)': False, 'contains(trying)': False, 'contains(unravel)': False, 'contains(film)': False, 'contains(every)': False, 'contains(when)': True, 'contains(does)': False, 'contains(give)': False, 'contains(me)': True, 'contains(same)': True, 'contains(clue)': False, 'contains(over)': False, 'contains(again)': False, 'contains(kind)': True, 'contains(fed)': False, 'contains(up)': False, 'contains(after)': False, 'contains(while)': True, 'contains(biggest)': False, 'contains(obviously)': False, 'contains(got)': True, 'contains(big)': False, 'contains(secret)': False, 'contains(hide)': False, 'contains(seems)': False, 'contains(want)': False, 'contains(completely)': False, 'contains(until)': False, 'contains(final)': False, 'contains(five)': False, 'contains(minutes)': False, 'contains(do)': True, 'contains(make)': True, 'contains(entertaining)': False, 'contains(thrilling)': False, 'contains(or)': False, 'contains(engaging)': False, 'contains(meantime)': False, 'contains(really)': False, 'contains(sad)': False, 'contains(part)': False, 'contains(arrow)': False, 'contains(both)': False, 'contains(dig)': False, 'contains(flicks)': False, 'contains(we)': False, 'contains(actually)': True, 'contains(figured)': False, 'contains(by)': True, 'contains(half)': False, 'contains(way)': True, 'contains(point)': False, 'contains(strangeness)': False, 'contains(did)': False, 'contains(start)': True, 'contains(little)': True, 'contains(bit)': False, 'contains(sense)': False, 'contains(still)': False, 'contains(more)': False, 'contains(guess)': False, 'contains(bottom)': False, 'contains(line)': False, 'contains(movies)': True, 'contains(should)': False, 'contains(always)': False, 'contains(sure)': False, 'contains(before)': False, 'contains(given)': False, 'contains(password)': False, 'contains(enter)': False, 'contains(understanding)': False, 'contains(mean)': False, 'contains(showing)': False, 'contains(melissa)': False, 'contains(sagemiller)': False, 'contains(running)': False, 'contains(away)': False, 'contains(visions)': False, 'contains(about)': True, 'contains(20)': False, 'contains(throughout)': False, 'contains(plain)': False, 'contains(lazy)': False, 'contains(!)': True, 'contains(okay)': False, 'contains(people)': False, 'contains(chasing)': False, 'contains(know)': False, 'contains(need)': False, 'contains(how)': True, 'contains(giving)': False, 'contains(us)': True, 'contains(different)': False, 'contains(offering)': False, 'contains(further)': False, 'contains(insight)': False, 'contains(down)': False, 'contains(apparently)': False, 'contains(studio)': False, 'contains(took)': False, 'contains(director)': False, 'contains(chopped)': False, 'contains(themselves)': False, 'contains(shows)': False, 'contains(might)': False, 'contains(ve)': False, 'contains(been)': False, 'contains(decent)': False, 'contains(here)': True, 'contains(somewhere)': False, 'contains(suits)': False, 'contains(decided)': False, 'contains(turning)': False, 'contains(music)': False, 'contains(video)': False, 'contains(edge)': False, 'contains(would)': False, 'contains(actors)': False, 'contains(although)': False, 'contains(wes)': False, 'contains(bentley)': False, 'contains(seemed)': False, 'contains(be)': True, 'contains(playing)': True, 'contains(exact)': False, 'contains(character)': False, 'contains(he)': True, 'contains(american)': False, 'contains(beauty)': False, 'contains(only)': True, 'contains(new)': False, 'contains(neighborhood)': False, 'contains(my)': False, 'contains(kudos)': False, 'contains(holds)': False, 'contains(own)': True, 'contains(entire)': False, 'contains(feeling)': False, 'contains(unraveling)': False, 'contains(overall)': False, 'contains(doesn)': False, 'contains(stick)': False, 'contains(because)': False, 'contains(entertain)': False, 'contains(confusing)': False, 'contains(rarely)': False, 'contains(excites)': False, 'contains(feels)': False, 'contains(redundant)': False, 'contains(runtime)': False, 'contains(despite)': False, 'contains(ending)': False, 'contains(explanation)': False, 'contains(craziness)': False, 'contains(came)': False, 'contains(oh)': False, 'contains(horror)': False, 'contains(slasher)': False, 'contains(flick)': False, 'contains(packaged)': False, 'contains(someone)': False, 'contains(assuming)': False, 'contains(genre)': False, 'contains(hot)': False, 'contains(kids)': False, 'contains(also)': True, 'contains(wrapped)': False, 'contains(production)': False, 'contains(years)': False, 'contains(ago)': False, 'contains(sitting)': False, 'contains(shelves)': False, 'contains(ever)': True, 'contains(whatever)': False, 'contains(skip)': False, 'contains(where)': True, 'contains(joblo)': False, 'contains(nightmare)': False, 'contains(elm)': False, 'contains(street)': False, 'contains(3)': False, 'contains(7)': False, 'contains(/)': False, 'contains(10)': False, 'contains(blair)': False, 'contains(witch)': False, 'contains(2)': False, 'contains(crow)': False, 'contains(9)': False, 'contains(salvation)': False, 'contains(4)': False, 'contains(stir)': False, 'contains(echoes)': False, 'contains(8)': False, 'contains(happy)': False, 'contains(bastard)': False, 'contains(quick)': True, 'contains(damn)': False, 'contains(y2k)': False, 'contains(bug)': False, 'contains(starring)': False, 'contains(jamie)': False, 'contains(lee)': False, 'contains(curtis)': False, 'contains(another)': False, 'contains(baldwin)': False, 'contains(brother)': False, 'contains(william)': False, 'contains(time)': False, 'contains(story)': False, 'contains(regarding)': False, 'contains(crew)': False, 'contains(tugboat)': False, 'contains(comes)': False, 'contains(across)': False, 'contains(deserted)': False, 'contains(russian)': False, 'contains(tech)': False, 'contains(ship)': False, 'contains(kick)': False, 'contains(power)': False, 'contains(within)': False, 'contains(gore)': False, 'contains(bringing)': False, 'contains(few)': False, 'contains(action)': True, 'contains(sequences)': False, 'contains(virus)': False, 'contains(empty)': False, 'contains(flash)': False, 'contains(substance)': False, 'contains(why)': False, 'contains(was)': False, 'contains(middle)': False, 'contains(nowhere)': False, 'contains(origin)': False, 'contains(pink)': False, 'contains(flashy)': False, 'contains(thing)': False, 'contains(hit)': False, 'contains(mir)': False, 'contains(course)': True, 'contains(donald)': False, 'contains(sutherland)': False, 'contains(stumbling)': False, 'contains(around)': False, 'contains(drunkenly)': False, 'contains(hey)': False, 'contains(let)': False, 'contains(some)': False, 'contains(robots)': False, 'contains(acting)': False, 'contains(below)': False, 'contains(average)': False, 'contains(likes)': False, 'contains(re)': True, 'contains(likely)': False, 'contains(work)': False, 'contains(halloween)': False, 'contains(h20)': False, 'contains(wasted)': False, 'contains(real)': False, 'contains(star)': False, 'contains(stan)': False, 'contains(winston)': False, 'contains(robot)': False, 'contains(design)': False, 'contains(schnazzy)': False, 'contains(cgi)': False, 'contains(occasional)': False, 'contains(shot)': False, 'contains(picking)': False, 'contains(brain)': False, 'contains(if)': True, 'contains(body)': False, 'contains(parts)': False, 'contains(turn)': False, 'contains(otherwise)': False, 'contains(much)': False, 'contains(sunken)': False, 'contains(jaded)': False, 'contains(viewer)': False, 'contains(thankful)': False, 'contains(invention)': False, 'contains(timex)': False, 'contains(indiglo)': False, 'contains(based)': False, 'contains(late)': False, 'contains(1960)': False, 'contains(television)': False, 'contains(show)': False, 'contains(name)': False, 'contains(mod)': False, 'contains(squad)': False, 'contains(tells)': False, 'contains(tale)': False, 'contains(three)': False, 'contains(reformed)': False, 'contains(criminals)': False, 'contains(under)': False, 'contains(employ)': False, 'contains(police)': False, 'contains(undercover)': True, 'contains(however)': True, 'contains(wrong)': True, 'contains(evidence)': False, 'contains(gets)': True, 'contains(stolen)': False, 'contains(immediately)': False, 'contains(suspicion)': False, 'contains(ads)': False, 'contains(cuts)': False, 'contains(claire)': False, 'contains(dane)': False, 'contains(nice)': False, 'contains(hair)': False, 'contains(cute)': False, 'contains(outfits)': False, 'contains(car)': False, 'contains(chases)': False, 'contains(stuff)': False, 'contains(blowing)': False, 'contains(sounds)': False, 'contains(first)': False, 'contains(fifteen)': False, 'contains(quickly)': False, 'contains(becomes)': False, 'contains(apparent)': False, 'contains(certainly)': False, 'contains(slick)': False, 'contains(looking)': False, 'contains(complete)': False, 'contains(costumes)': False, 'contains(isn)': False, 'contains(enough)': False, 'contains(best)': True, 'contains(described)': False, 'contains(cross)': False, 'contains(between)': True, 'contains(hour)': False, 'contains(long)': False, 'contains(cop)': False, 'contains(stretched)': False, 'contains(span)': False, 'contains(single)': False, 'contains(clich)': False, 'contains(matter)': False, 'contains(elements)': False, 'contains(recycled)': False, 'contains(everything)': True, 'contains(already)': False, 'contains(seen)': False, 'contains(nothing)': False, 'contains(spectacular)': False, 'contains(sometimes)': False, 'contains(bordering)': False, 'contains(wooden)': False, 'contains(danes)': False, 'contains(omar)': False, 'contains(epps)': False, 'contains(deliver)': False, 'contains(their)': False, 'contains(lines)': False, 'contains(bored)': False, 'contains(transfers)': False, 'contains(onto)': False, 'contains(escape)': False, 'contains(relatively)': False, 'contains(unscathed)': False, 'contains(giovanni)': False, 'contains(ribisi)': False, 'contains(plays)': False, 'contains(resident)': False, 'contains(crazy)': False, 'contains(man)': False, 'contains(ultimately)': False, 'contains(being)': False, 'contains(worth)': True, 'contains(watching)': False, 'contains(unfortunately)': False, 'contains(save)': False, 'contains(convoluted)': False, 'contains(apart)': False, 'contains(occupying)': False, 'contains(screen)': True, 'contains(young)': False, 'contains(cast)': False, 'contains(clothes)': False, 'contains(hip)': False, 'contains(soundtrack)': False, 'contains(appears)': False, 'contains(geared)': False, 'contains(towards)': False, 'contains(teenage)': False, 'contains(mindset)': False, 'contains(r)': False, 'contains(rating)': False, 'contains(content)': False, 'contains(justify)': False, 'contains(juvenile)': False, 'contains(older)': False, 'contains(information)': False, 'contains(literally)': False, 'contains(spoon)': False, 'contains(hard)': False, 'contains(instead)': False, 'contains(telling)': False, 'contains(dialogue)': False, 'contains(poorly)': False, 'contains(written)': False, 'contains(extremely)': False, 'contains(predictable)': False, 'contains(progresses)': False, 'contains(won)': False, 'contains(care)': False, 'contains(heroes)': False, 'contains(any)': False, 'contains(jeopardy)': False, 'contains(ll)': False, 'contains(aren)': False, 'contains(basing)': False, 'contains(nobody)': False, 'contains(remembers)': False, 'contains(questionable)': False, 'contains(wisdom)': False, 'contains(especially)': True, 'contains(considers)': False, 'contains(target)': False, 'contains(fact)': False, 'contains(number)': False, 'contains(memorable)': False, 'contains(can)': False, 'contains(counted)': False, 'contains(hand)': False, 'contains(missing)': False, 'contains(finger)': False, 'contains(times)': False, 'contains(checked)': False, 'contains(six)': False, 'contains(clear)': False, 'contains(indication)': False, 'contains(them)': True, 'contains(than)': False, 'contains(cash)': False, 'contains(spending)': False, 'contains(dollar)': False, 'contains(judging)': False, 'contains(rash)': False, 'contains(awful)': False, 'contains(seeing)': True, 'contains(avoid)': False, 'contains(at)': False, 'contains(costs)': False, 'contains(quest)': False, 'contains(camelot)': False, 'contains(warner)': False, 'contains(bros)': False, 'contains(feature)': False, 'contains(length)': False, 'contains(fully)': False, 'contains(animated)': False, 'contains(steal)': False, 'contains(clout)': False, 'contains(disney)': False, 'contains(cartoon)': False, 'contains(empire)': False, 'contains(mouse)': False, 'contains(reason)': False, 'contains(worried)': False, 'contains(other)': True, 'contains(recent)': False, 'contains(challenger)': False, 'contains(throne)': False, 'contains(last)': False, 'contains(fall)': False, 'contains(promising)': False, 'contains(flawed)': False, 'contains(20th)': False, 'contains(century)': False, 'contains(fox)': False, 'contains(anastasia)': False, 'contains(hercules)': False, 'contains(lively)': False, 'contains(colorful)': False, 'contains(palate)': False, 'contains(had)': False, 'contains(beat)': False, 'contains(hands)': False, 'contains(crown)': False, 'contains(1997)': False, 'contains(piece)': False, 'contains(animation)': False, 'contains(year)': False, 'contains(contest)': False, 'contains(arrival)': False, 'contains(magic)': False, 'contains(kingdom)': False, 'contains(mediocre)': False, 'contains(--)': True, 'contains(d)': False, 'contains(pocahontas)': False, 'contains(those)': False, 'contains(keeping)': False, 'contains(score)': False, 'contains(nearly)': False, 'contains(dull)': False, 'contains(revolves)': False, 'contains(adventures)': False, 'contains(free)': False, 'contains(spirited)': False, 'contains(kayley)': False, 'contains(voiced)': False, 'contains(jessalyn)': False, 'contains(gilsig)': False, 'contains(early)': True, 'contains(daughter)': False, 'contains(belated)': False, 'contains(knight)': False, 'contains(king)': False, 'contains(arthur)': False, 'contains(round)': False, 'contains(table)': False, 'contains(dream)': False, 'contains(follow)': False, 'contains(father)': False, 'contains(footsteps)': False, 'contains(she)': True, 'contains(chance)': False, 'contains(evil)': False, 'contains(warlord)': False, 'contains(ruber)': False, 'contains(gary)': False, 'contains(oldman)': False, 'contains(ex)': False, 'contains(gone)': False, 'contains(steals)': False, 'contains(magical)': False, 'contains(sword)': False, 'contains(excalibur)': False, 'contains(accidentally)': False, 'contains(loses)': False, 'contains(dangerous)': True, 'contains(booby)': False, 'contains(trapped)': False, 'contains(forest)': False, 'contains(help)': True, 'contains(hunky)': False, 'contains(blind)': False, 'contains(timberland)': False, 'contains(dweller)': False, 'contains(garrett)': False, 'contains(carey)': False, 'contains(elwes)': False, 'contains(headed)': False, 'contains(dragon)': False, 'contains(eric)': False, 'contains(idle)': False, 'contains(rickles)': False, 'contains(arguing)': False, 'contains(itself)': False, 'contains(able)': False, 'contains(medieval)': False, 'contains(sexist)': False, 'contains(prove)': False, 'contains(fighter)': False, 'contains(side)': False, 'contains(pure)': False, 'contains(showmanship)': False, 'contains(essential)': False, 'contains(element)': False, 'contains(expected)': False, 'contains(climb)': False, 'contains(high)': False, 'contains(ranks)': False, 'contains(differentiates)': False, 'contains(something)': False, 'contains(saturday)': False, 'contains(morning)': False, 'contains(subpar)': False, 'contains(instantly)': False, 'contains(forgettable)': False, 'contains(songs)': False, 'contains(integrated)': False, 'contains(computerized)': False, 'contains(footage)': False, 'contains(compare)': False, 'contains(run)': False, 'contains(angry)': False, 'contains(ogre)': False, 'contains(herc)': False, 'contains(battle)': False, 'contains(hydra)': False, 'contains(rest)': False, 'contains(case)': False, 'contains(stink)': False, 'contains(none)': False, 'contains(remotely)': False, 'contains(interesting)': False, 'contains(race)': False, 'contains(bland)': False, 'contains(end)': False, 'contains(tie)': False, 'contains(win)': False, 'contains(comedy)': True, 'contains(shtick)': False, 'contains(awfully)': False, 'contains(cloying)': False, 'contains(least)': True, 'contains(signs)': False, 'contains(pulse)': False, 'contains(fans)': False, \"contains(-')\": False, 'contains(90s)': False, 'contains(tgif)': False, 'contains(will)': True, 'contains(thrilled)': False, 'contains(jaleel)': False, 'contains(urkel)': False, 'contains(white)': False, 'contains(bronson)': False, 'contains(balki)': False, 'contains(pinchot)': False, 'contains(sharing)': False, 'contains(nicely)': False, 'contains(realized)': False, 'contains(though)': False, 'contains(m)': False, 'contains(loss)': False, 'contains(recall)': False, 'contains(specific)': False, 'contains(providing)': False, 'contains(voice)': False, 'contains(talent)': False, 'contains(enthusiastic)': False, 'contains(paired)': False, 'contains(singers)': False, 'contains(sound)': False, 'contains(musical)': False, 'contains(moments)': False, 'contains(jane)': False, 'contains(seymour)': False, 'contains(celine)': False, 'contains(dion)': False, 'contains(must)': False, 'contains(strain)': False, 'contains(through)': False, 'contains(aside)': False, 'contains(children)': False, 'contains(probably)': False, 'contains(adults)': False, 'contains(grievous)': False, 'contains(error)': False, 'contains(lack)': False, 'contains(personality)': False, 'contains(learn)': False, 'contains(goes)': False, 'contains(synopsis)': False, 'contains(mentally)': False, 'contains(unstable)': False, 'contains(undergoing)': False, 'contains(psychotherapy)': False, 'contains(saves)': False, 'contains(boy)': False, 'contains(potentially)': False, 'contains(fatal)': False, 'contains(falls)': False, 'contains(love)': False, 'contains(mother)': False, 'contains(fledgling)': False, 'contains(restauranteur)': False, 'contains(unsuccessfully)': False, 'contains(attempting)': False, 'contains(gain)': False, 'contains(woman)': True, 'contains(favor)': False, 'contains(takes)': False, 'contains(pictures)': False, 'contains(kills)': False, 'contains(comments)': True, 'contains(stalked)': False, 'contains(yet)': False, 'contains(seemingly)': False, 'contains(endless)': True, 'contains(string)': False, 'contains(spurned)': False, 'contains(psychos)': False, 'contains(getting)': True, 'contains(revenge)': False, 'contains(type)': False, 'contains(stable)': False, 'contains(category)': False, 'contains(1990s)': False, 'contains(industry)': False, 'contains(theatrical)': False, 'contains(direct)': False, 'contains(proliferation)': False, 'contains(may)': False, 'contains(due)': False, 'contains(typically)': False, 'contains(inexpensive)': False, 'contains(produce)': False, 'contains(special)': False, 'contains(effects)': False, 'contains(stars)': False, 'contains(serve)': False, 'contains(vehicles)': False, 'contains(nudity)': False, 'contains(allowing)': False, 'contains(frequent)': False, 'contains(night)': False, 'contains(cable)': False, 'contains(wavers)': False, 'contains(slightly)': False, 'contains(norm)': False, 'contains(respect)': False, 'contains(psycho)': False, 'contains(never)': True, 'contains(affair)': False, 'contains(;)': False, 'contains(contrary)': False, 'contains(rejected)': False, 'contains(rather)': False, 'contains(lover)': False, 'contains(wife)': True, 'contains(husband)': False, 'contains(entry)': False, 'contains(doomed)': False, 'contains(collect)': False, 'contains(dust)': False, 'contains(viewed)': False, 'contains(midnight)': False, 'contains(provide)': False, 'contains(suspense)': False, 'contains(sets)': False, 'contains(interspersed)': False, 'contains(opening)': False, 'contains(credits)': False, 'contains(instance)': False, 'contains(serious)': False, 'contains(sounding)': False, 'contains(narrator)': False, 'contains(spouts)': False, 'contains(statistics)': False, 'contains(stalkers)': False, 'contains(ponders)': False, 'contains(cause)': False, 'contains(stalk)': False, 'contains(implicitly)': False, 'contains(implied)': False, 'contains(men)': False, 'contains(shown)': False, 'contains(snapshot)': False, 'contains(actor)': False, 'contains(jay)': False, 'contains(underwood)': False, 'contains(states)': False, 'contains(daryl)': False, 'contains(gleason)': False, 'contains(stalker)': False, 'contains(brooke)': False, 'contains(daniels)': False, 'contains(meant)': False, 'contains(called)': False, 'contains(guesswork)': False, 'contains(required)': False, 'contains(proceeds)': False, 'contains(begins)': False, 'contains(obvious)': False, 'contains(sequence)': False, 'contains(contrived)': False, 'contains(quite)': False, 'contains(brings)': False, 'contains(victim)': False, 'contains(together)': False, 'contains(obsesses)': False, 'contains(follows)': False, 'contains(tries)': True, 'contains(woo)': False, 'contains(plans)': False, 'contains(become)': False, 'contains(desperate)': False, 'contains(elaborate)': False, 'contains(include)': False, 'contains(cliche)': False, 'contains(murdered)': False, 'contains(pet)': False, 'contains(require)': False, 'contains(found)': False, 'contains(exception)': False, 'contains(cat)': False, 'contains(shower)': False, 'contains(events)': False, 'contains(lead)': True, 'contains(inevitable)': False, 'contains(showdown)': False, 'contains(survives)': False, 'contains(invariably)': False, 'contains(conclusion)': False, 'contains(turkey)': False, 'contains(uniformly)': False, 'contains(adequate)': False, 'contains(anything)': False, 'contains(home)': False, 'contains(either)': False, 'contains(turns)': False, 'contains(toward)': False, 'contains(melodrama)': False, 'contains(overdoes)': False, 'contains(words)': False, 'contains(manages)': False, 'contains(creepy)': False, 'contains(pass)': False, 'contains(demands)': False, 'contains(maryam)': False, 'contains(abo)': False, 'contains(close)': False, 'contains(played)': True, 'contains(bond)': False, 'contains(chick)': False, 'contains(living)': False, 'contains(daylights)': False, 'contains(equally)': False, 'contains(title)': False, 'contains(ditzy)': False, 'contains(strong)': False, 'contains(independent)': False, 'contains(business)': False, 'contains(owner)': False, 'contains(needs)': False, 'contains(proceed)': False, 'contains(example)': False, 'contains(suspicions)': False, 'contains(ensure)': False, 'contains(use)': False, 'contains(excuse)': False, 'contains(decides)': False, 'contains(return)': False, 'contains(toolbox)': False, 'contains(left)': False, 'contains(place)': True, 'contains(house)': False, 'contains(leave)': False, 'contains(door)': False, 'contains(answers)': False, 'contains(opens)': False, 'contains(wanders)': False, 'contains(returns)': False, 'contains(enters)': False, 'contains(our)': False, 'contains(heroine)': False, 'contains(danger)': False, 'contains(somehow)': False, 'contains(parked)': False, 'contains(front)': False, 'contains(right)': False, 'contains(oblivious)': False, 'contains(presence)': False, 'contains(inside)': False, 'contains(whole)': False, 'contains(episode)': False, 'contains(places)': False, 'contains(incredible)': False, 'contains(suspension)': False, 'contains(disbelief)': False, 'contains(questions)': False, 'contains(validity)': False, 'contains(intelligence)': False, 'contains(receives)': False, 'contains(highly)': False, 'contains(derivative)': False, 'contains(somewhat)': False, 'contains(boring)': False, 'contains(cannot)': False, 'contains(watched)': False, 'contains(rated)': False, 'contains(mostly)': False, 'contains(several)': False, 'contains(murder)': False, 'contains(brief)': True, 'contains(strip)': False, 'contains(bar)': False, 'contains(offensive)': False, 'contains(many)': True, 'contains(thrillers)': False, 'contains(mood)': False, 'contains(stake)': False, 'contains(else)': False, 'contains(capsule)': True, 'contains(2176)': False, 'contains(planet)': False, 'contains(mars)': False, 'contains(taking)': False, 'contains(custody)': False, 'contains(accused)': False, 'contains(murderer)': False, 'contains(face)': False, 'contains(menace)': False, 'contains(lot)': False, 'contains(fighting)': False, 'contains(john)': False, 'contains(carpenter)': False, 'contains(reprises)': False, 'contains(ideas)': False, 'contains(previous)': False, 'contains(assault)': False, 'contains(precinct)': False, 'contains(13)': False, 'contains(homage)': False, 'contains(himself)': False, 'contains(0)': False, 'contains(+)': False, 'contains(believes)': False, 'contains(fight)': True, 'contains(horrible)': False, 'contains(writer)': False, 'contains(supposedly)': False, 'contains(expert)': False, 'contains(mistake)': False, 'contains(ghosts)': False, 'contains(drawn)': False, 'contains(humans)': False, 'contains(surprisingly)': False, 'contains(low)': False, 'contains(powered)': False, 'contains(alien)': False, 'contains(addition)': False, 'contains(anybody)': False, 'contains(made)': False, 'contains(grounds)': False, 'contains(sue)': False, 'contains(chock)': False, 'contains(full)': False, 'contains(pieces)': False, 'contains(prince)': False, 'contains(darkness)': False, 'contains(surprising)': False, 'contains(managed)': False, 'contains(fit)': False, 'contains(admittedly)': False, 'contains(novel)': False, 'contains(science)': False, 'contains(fiction)': False, 'contains(experience)': False, 'contains(terraformed)': False, 'contains(walk)': False, 'contains(surface)': False, 'contains(without)': False, 'contains(breathing)': False, 'contains(gear)': False, 'contains(budget)': False, 'contains(mentioned)': False, 'contains(gravity)': False, 'contains(increased)': False, 'contains(earth)': False, 'contains(easier)': False, 'contains(society)': False, 'contains(changed)': False, 'contains(advanced)': False, 'contains(culture)': False, 'contains(women)': False, 'contains(positions)': False, 'contains(control)': False, 'contains(view)': False, 'contains(stagnated)': False, 'contains(female)': False, 'contains(beyond)': False, 'contains(minor)': False, 'contains(technological)': False, 'contains(advances)': False, 'contains(less)': False, 'contains(175)': False, 'contains(expect)': False, 'contains(change)': False, 'contains(ten)': False, 'contains(basic)': False, 'contains(common)': False, 'contains(except)': False, 'contains(yes)': False, 'contains(replaced)': False, 'contains(tacky)': False, 'contains(rundown)': False, 'contains(martian)': False, 'contains(mining)': False, 'contains(colony)': False, 'contains(having)': False, 'contains(criminal)': False, 'contains(napolean)': False, 'contains(wilson)': False, 'contains(desolation)': False, 'contains(williams)': False, 'contains(facing)': False, 'contains(hoodlums)': False, 'contains(automatic)': False, 'contains(weapons)': False, 'contains(nature)': False, 'contains(behave)': False, 'contains(manner)': False, 'contains(essentially)': False, 'contains(human)': False, 'contains(savages)': False, 'contains(lapse)': False, 'contains(imagination)': False, 'contains(told)': False, 'contains(flashback)': False, 'contains(entirely)': False, 'contains(filmed)': False, 'contains(almost)': False, 'contains(tones)': False, 'contains(red)': False, 'contains(yellow)': False, 'contains(black)': False, 'contains(powerful)': False, 'contains(scene)': True, 'contains(train)': True, 'contains(rushing)': False, 'contains(heavy)': False, 'contains(sadly)': False, 'contains(buildup)': False, 'contains(terror)': False, 'contains(creates)': False, 'contains(looks)': True, 'contains(fugitive)': False, 'contains(wannabes)': False, 'contains(rock)': False, 'contains(band)': False, 'contains(kiss)': False, 'contains(building)': False, 'contains(bunch)': False, 'contains(sudden)': False, 'contains(jump)': False, 'contains(sucker)': False, 'contains(thinking)': False, 'contains(scary)': False, 'contains(happening)': False, 'contains(standard)': False, 'contains(haunted)': False, 'contains(shock)': False, 'contains(great)': True, 'contains(newer)': False, 'contains(unimpressive)': False, 'contains(digital)': False, 'contains(decapitations)': False, 'contains(fights)': False, 'contains(short)': False, 'contains(stretch)': False, 'contains(release)': False, 'contains(mission)': False, 'contains(panned)': False, 'contains(reviewers)': False, 'contains(better)': False, 'contains(rate)': False, 'contains(scale)': False, 'contains(following)': False, 'contains(showed)': False, 'contains(liked)': False, 'contains(moderately)': False, 'contains(classic)': False, 'contains(comment)': False, 'contains(twice)': False, 'contains(ask)': False, 'contains(yourself)': False, 'contains(8mm)': False, 'contains(eight)': True, 'contains(millimeter)': False, 'contains(wholesome)': False, 'contains(surveillance)': False, 'contains(sight)': False, 'contains(values)': False, 'contains(becoming)': False, 'contains(enmeshed)': False, 'contains(seedy)': False, 'contains(sleazy)': False, 'contains(underworld)': False, 'contains(hardcore)': False, 'contains(pornography)': False, 'contains(bubbling)': False, 'contains(beneath)': False, 'contains(town)': False, 'contains(americana)': False, 'contains(sordid)': False, 'contains(sick)': False, 'contains(depraved)': False, 'contains(necessarily)': False, 'contains(stop)': True, 'contains(order)': False, 'contains(satisfy)': False, 'contains(twisted)': False, 'contains(desires)': False, 'contains(position)': False, 'contains(influence)': False, 'contains(kinds)': False, 'contains(demented)': False, 'contains(talking)': False, 'contains(snuff)': False, 'contains(supposed)': False, 'contains(documentaries)': False, 'contains(victims)': False, 'contains(brutalized)': False, 'contains(killed)': False, 'contains(camera)': False, 'contains(joel)': False, 'contains(schumacher)': False, 'contains(credit)': False, 'contains(batman)': False, 'contains(robin)': False, 'contains(kill)': False, 'contains(forever)': False, 'contains(client)': False, 'contains(thirds)': False, 'contains(unwind)': False, 'contains(fairly)': True, 'contains(conventional)': False, 'contains(persons)': False, 'contains(drama)': False, 'contains(albeit)': False, 'contains(particularly)': False, 'contains(unsavory)': False, 'contains(core)': False, 'contains(threatening)': False, 'contains(along)': True, 'contains(explodes)': False, 'contains(violence)': False, 'contains(think)': False, 'contains(finally)': False, 'contains(tags)': False, 'contains(ridiculous)': False, 'contains(self)': False, 'contains(righteous)': False, 'contains(finale)': False, 'contains(drags)': False, 'contains(unpleasant)': False, 'contains(trust)': False, 'contains(waste)': False, 'contains(hours)': False, 'contains(nicolas)': False, 'contains(snake)': False, 'contains(eyes)': False, 'contains(cage)': False, 'contains(private)': False, 'contains(investigator)': False, 'contains(tom)': False, 'contains(welles)': False, 'contains(hired)': False, 'contains(wealthy)': False, 'contains(philadelphia)': False, 'contains(widow)': False, 'contains(determine)': False, 'contains(whether)': False, 'contains(reel)': False, 'contains(safe)': False, 'contains(documents)': False, 'contains(girl)': False, 'contains(assignment)': True, 'contains(factly)': False, 'contains(puzzle)': False, 'contains(neatly)': False, 'contains(specialized)': False, 'contains(skills)': False, 'contains(training)': False, 'contains(easy)': False, 'contains(cops)': False, 'contains(toilet)': False, 'contains(tanks)': False, 'contains(clues)': False, 'contains(deeper)': False, 'contains(digs)': False, 'contains(investigation)': False, 'contains(obsessed)': False, 'contains(george)': False, 'contains(c)': False, 'contains(scott)': False, 'contains(paul)': False, 'contains(schrader)': False, 'contains(occasionally)': False, 'contains(flickering)': False, 'contains(whirs)': False, 'contains(sprockets)': False, 'contains(winding)': False, 'contains(projector)': False, 'contains(reminding)': False, 'contains(task)': False, 'contains(hints)': False, 'contains(toll)': False, 'contains(lovely)': False, 'contains(catherine)': False, 'contains(keener)': False, 'contains(frustrated)': False, 'contains(cleveland)': False, 'contains(ugly)': False, 'contains(split)': False, 'contains(level)': False, 'contains(harrisburg)': False, 'contains(pa)': False, 'contains(condemn)': False, 'contains(condone)': False, 'contains(subject)': False, 'contains(exploits)': False, 'contains(irony)': False, 'contains(seven)': False, 'contains(scribe)': False, 'contains(andrew)': False, 'contains(kevin)': True, 'contains(walker)': False, 'contains(vision)': False, 'contains(lane)': False, 'contains(limited)': False, 'contains(hollywood)': False, 'contains(product)': False, 'contains(snippets)': False, 'contains(covering)': False, 'contains(later)': False, 'contains(joaquin)': False, 'contains(phoenix)': False, 'contains(far)': False, 'contains(adult)': False, 'contains(bookstore)': False, 'contains(flunky)': False, 'contains(max)': False, 'contains(california)': False, 'contains(cover)': False, 'contains(horrid)': False, 'contains(screened)': False, 'contains(familiar)': False, 'contains(revelation)': False, 'contains(sexual)': False, 'contains(deviants)': False, 'contains(indeed)': False, 'contains(monsters)': False, 'contains(everyday)': False, 'contains(neither)': False, 'contains(super)': False, 'contains(nor)': False, 'contains(shocking)': False, 'contains(banality)': False, 'contains(exactly)': False, 'contains(felt)': False, 'contains(weren)': False, 'contains(nine)': False, 'contains(laughs)': False, 'contains(months)': False, 'contains(terrible)': False, 'contains(mr)': False, 'contains(hugh)': False, 'contains(grant)': False, 'contains(huge)': False, 'contains(dork)': False, 'contains(oral)': False, 'contains(sex)': False, 'contains(prostitution)': False, 'contains(referring)': False, 'contains(bugs)': False, 'contains(annoying)': False, 'contains(adam)': False, 'contains(sandler)': False, 'contains(jim)': False, 'contains(carrey)': False, 'contains(eye)': False, 'contains(flutters)': False, 'contains(nervous)': False, 'contains(smiles)': False, 'contains(slapstick)': False, 'contains(fistfight)': False, 'contains(delivery)': False, 'contains(room)': False, 'contains(culminating)': False, 'contains(joan)': False, 'contains(cusack)': False, 'contains(lap)': False, 'contains(paid)': False, 'contains($)': False, 'contains(60)': False, 'contains(included)': False, 'contains(obscene)': False, 'contains(double)': False, 'contains(entendres)': False, 'contains(obstetrician)': False, 'contains(pregnant)': False, 'contains(pussy)': False, 'contains(size)': False, 'contains(hairs)': False, 'contains(coat)': False, 'contains(nonetheless)': False, 'contains(exchange)': False, 'contains(cookie)': False, 'contains(cutter)': False, 'contains(originality)': False, 'contains(humor)': False, 'contains(successful)': False, 'contains(child)': False, 'contains(psychiatrist)': False, 'contains(psychologist)': False, 'contains(scriptwriters)': False, 'contains(could)': False, 'contains(inject)': False, 'contains(unfunny)': False, 'contains(kid)': False, 'contains(dad)': False, 'contains(asshole)': False, 'contains(eyelashes)': False, 'contains(offers)': False, 'contains(smile)': False, 'contains(responds)': False, 'contains(english)': False, 'contains(accent)': False, 'contains(attitude)': False, 'contains(possibly)': False, 'contains(_huge_)': False, 'contains(beside)': False, 'contains(includes)': False, 'contains(needlessly)': False, 'contains(stupid)': False, 'contains(jokes)': False, 'contains(olds)': False, 'contains(everyone)': False, 'contains(shakes)': False, 'contains(anyway)': False, 'contains(finds)': False, 'contains(usual)': False, 'contains(reaction)': False, 'contains(fluttered)': False, 'contains(paves)': False, 'contains(possible)': False, 'contains(pregnancy)': False, 'contains(birth)': False, 'contains(gag)': False, 'contains(book)': False, 'contains(friend)': False, 'contains(arnold)': True, 'contains(provides)': False, 'contains(cacophonous)': False, 'contains(funny)': True, 'contains(beats)': False, 'contains(costumed)': False, 'contains(arnie)': False, 'contains(dinosaur)': False, 'contains(draw)': False, 'contains(parallels)': False, 'contains(toy)': False, 'contains(store)': False, 'contains(jeff)': False, 'contains(goldblum)': False, 'contains(hid)': False, 'contains(dreadful)': False, 'contains(hideaway)': False, 'contains(artist)': False, 'contains(fear)': False, 'contains(simultaneous)': False, 'contains(longing)': False, 'contains(commitment)': False, 'contains(doctor)': False, 'contains(recently)': False, 'contains(switch)': False, 'contains(veterinary)': False, 'contains(medicine)': False, 'contains(obstetrics)': False, 'contains(joke)': False, 'contains(old)': False, 'contains(foreign)': False, 'contains(guy)': True, 'contains(mispronounces)': False, 'contains(stereotype)': False, 'contains(say)': False, 'contains(yakov)': False, 'contains(smirnov)': False, 'contains(favorite)': False, 'contains(vodka)': False, 'contains(hence)': False, 'contains(take)': False, 'contains(volvo)': False, 'contains(nasty)': False, 'contains(unamusing)': False, 'contains(heads)': False, 'contains(simultaneously)': False, 'contains(groan)': False, 'contains(failure)': False, 'contains(loud)': False, 'contains(failed)': False, 'contains(uninspired)': False, 'contains(lunacy)': False, 'contains(sunset)': False, 'contains(boulevard)': False, 'contains(arrest)': False, 'contains(please)': False, 'contains(caught)': False, 'contains(pants)': False, 'contains(bring)': False, 'contains(theaters)': False, 'contains(faces)': False, 'contains(90)': False, 'contains(forced)': False, 'contains(unauthentic)': False, 'contains(anyone)': False, 'contains(q)': False, 'contains(80)': False, 'contains(sorry)': False, 'contains(money)': False, 'contains(unfulfilled)': False, 'contains(desire)': False, 'contains(spend)': False, 'contains(bucks)': False, 'contains(call)': False, 'contains(road)': False, 'contains(trip)': False, 'contains(walking)': False, 'contains(wounded)': False, 'contains(stellan)': False, 'contains(skarsg)': False, 'contains(rd)': False, 'contains(convincingly)': False, 'contains(zombified)': False, 'contains(drunken)': False, 'contains(loser)': False, 'contains(difficult)': True, 'contains(smelly)': False, 'contains(boozed)': False, 'contains(reliable)': False, 'contains(swedish)': False, 'contains(adds)': False, 'contains(depth)': False, 'contains(significance)': False, 'contains(plodding)': False, 'contains(aberdeen)': False, 'contains(sentimental)': False, 'contains(painfully)': False, 'contains(mundane)': False, 'contains(european)': False, 'contains(playwright)': False, 'contains(august)': False, 'contains(strindberg)': False, 'contains(built)': False, 'contains(career)': False, 'contains(families)': False, 'contains(relationships)': False, 'contains(paralyzed)': False, 'contains(secrets)': False, 'contains(unable)': False, 'contains(express)': False, 'contains(longings)': False, 'contains(accurate)': False, 'contains(reflection)': False, 'contains(strives)': False, 'contains(focusing)': False, 'contains(pairing)': False, 'contains(alcoholic)': False, 'contains(tomas)': False, 'contains(alienated)': False, 'contains(openly)': False, 'contains(hostile)': False, 'contains(yuppie)': False, 'contains(kaisa)': False, 'contains(lena)': False, 'contains(headey)': False, 'contains(gossip)': False, 'contains(haven)': False, 'contains(spoken)': False, 'contains(wouldn)': False, 'contains(norway)': False, 'contains(scotland)': False, 'contains(automobile)': False, 'contains(charlotte)': False, 'contains(rampling)': False, 'contains(sand)': False, 'contains(rotting)': False, 'contains(hospital)': False, 'contains(bed)': False, 'contains(cancer)': False, 'contains(soap)': False, 'contains(opera)': False, 'contains(twist)': False, 'contains(days)': False, 'contains(live)': False, 'contains(blitzed)': False, 'contains(step)': False, 'contains(foot)': False, 'contains(plane)': False, 'contains(hits)': False, 'contains(open)': False, 'contains(loathing)': False, 'contains(each)': True, 'contains(periodic)': False, 'contains(stops)': True, 'contains(puke)': False, 'contains(dashboard)': False, 'contains(whenever)': False, 'contains(muttering)': False, 'contains(rotten)': False, 'contains(turned)': False, 'contains(sloshed)': False, 'contains(viewpoint)': False, 'contains(recognizes)': False, 'contains(apple)': False, 'contains(hasn)': False, 'contains(fallen)': False, 'contains(tree)': False, 'contains(nosebleeds)': False, 'contains(snorting)': False, 'contains(coke)': False, 'contains(sabotages)': False, 'contains(personal)': False, 'contains(indifference)': False, 'contains(restrain)': False, 'contains(vindictive)': False, 'contains(temper)': False, 'contains(ain)': False, 'contains(pair)': False, 'contains(true)': False, 'contains(notes)': False, 'contains(unspoken)': False, 'contains(familial)': False, 'contains(empathy)': False, 'contains(note)': False, 'contains(repetitively)': False, 'contains(bitchy)': False, 'contains(screenwriters)': False, 'contains(kristin)': False, 'contains(amundsen)': False, 'contains(hans)': False, 'contains(petter)': False, 'contains(moland)': False, 'contains(fabricate)': False, 'contains(series)': True, 'contains(contrivances)': False, 'contains(propel)': False, 'contains(forward)': False, 'contains(roving)': False, 'contains(hooligans)': False, 'contains(drunks)': False, 'contains(nosy)': False, 'contains(flat)': False, 'contains(tires)': False, 'contains(figure)': False, 'contains(schematic)': False, 'contains(convenient)': False, 'contains(narrative)': False, 'contains(reach)': False, 'contains(unveil)': False, 'contains(dark)': False, 'contains(past)': False, 'contains(simplistic)': False, 'contains(devices)': False, 'contains(trivialize)': False, 'contains(conflict)': False, 'contains(mainstays)': False, 'contains(wannabe)': False, 'contains(exists)': False, 'contains(purely)': False, 'contains(sake)': False, 'contains(weak)': False, 'contains(unimaginative)': False, 'contains(casting)': False, 'contains(thwarts)': False, 'contains(pivotal)': False, 'contains(role)': False, 'contains(were)': False, 'contains(stronger)': False, 'contains(actress)': False, 'contains(perhaps)': False, 'contains(coast)': True, 'contains(performances)': False, 'contains(moody)': False, 'contains(haunting)': False, 'contains(cinematography)': False, 'contains(rendering)': False, 'contains(pastoral)': False, 'contains(ghost)': False, 'contains(reference)': False, 'contains(certain)': False, 'contains(superior)': False, 'contains(indie)': False, 'contains(intentional)': False, 'contains(busy)': False, 'contains(using)': False, 'contains(furrowed)': False, 'contains(brow)': False, 'contains(convey)': False, 'contains(twitch)': False, 'contains(insouciance)': False, 'contains(paying)': False, 'contains(attention)': False, 'contains(maybe)': False, 'contains(doing)': False, 'contains(reveal)': False, 'contains(worthwhile)': False, 'contains(earlier)': False, 'contains(released)': False, 'contains(2001)': False, 'contains(jonathan)': False, 'contains(nossiter)': False, 'contains(captivating)': False, 'contains(wonders)': False, 'contains(disturbed)': False, 'contains(parental)': False, 'contains(figures)': False, 'contains(bound)': False, 'contains(ceremonial)': False, 'contains(wedlock)': False, 'contains(differences)': False, 'contains(presented)': False, 'contains(significant)': False, 'contains(luminous)': False, 'contains(diva)': False, 'contains(preening)': False, 'contains(static)': False, 'contains(solid)': False, 'contains(performance)': False, 'contains(pathetic)': False, 'contains(drunk)': False, 'contains(emote)': False, 'contains(besides)': False, 'contains(catatonic)': False, 'contains(sorrow)': False, 'contains(genuine)': False, 'contains(ferocity)': False, 'contains(sexually)': False, 'contains(charged)': False, 'contains(frisson)': False, 'contains(during)': False, 'contains(understated)': False, 'contains(confrontations)': False, 'contains(suggest)': False, 'contains(gray)': False, 'contains(zone)': False, 'contains(complications)': False, 'contains(accompany)': False, 'contains(torn)': False, 'contains(romance)': False, 'contains(stifled)': False, 'contains(curiosity)': False, 'contains(thoroughly)': False, 'contains(explores)': False, 'contains(neurotic)': False, 'contains(territory)': False, 'contains(delving)': False, 'contains(americanization)': False, 'contains(greece)': False, 'contains(mysticism)': False, 'contains(illusion)': False, 'contains(deflect)': False, 'contains(pain)': False, 'contains(overloaded)': False, 'contains(willing)': False, 'contains(come)': False, 'contains(traditional)': False, 'contains(ambitious)': False, 'contains(sleepwalk)': False, 'contains(rhythms)': False, 'contains(timing)': False, 'contains(driven)': False, 'contains(stories)': False, 'contains(complexities)': False, 'contains(depressing)': False, 'contains(answer)': False, 'contains(lawrence)': False, 'contains(kasdan)': False, 'contains(trite)': False, 'contains(useful)': False, 'contains(grand)': False, 'contains(canyon)': False, 'contains(steve)': False, 'contains(martin)': False, 'contains(mogul)': False, 'contains(pronounces)': False, 'contains(riddles)': False, 'contains(answered)': False, 'contains(advice)': False, 'contains(heart)': False, 'contains(french)': False, 'contains(sees)': True, 'contains(parents)': False, 'contains(tim)': False, 'contains(roth)': False, 'contains(oops)': False, 'contains(vows)': False, 'contains(taught)': False, 'contains(musketeer)': False, 'contains(dude)': False, 'contains(used)': True, 'contains(fourteen)': False, 'contains(arrgh)': False, 'contains(swish)': False, 'contains(zzzzzzz)': False, 'contains(original)': False, 'contains(lacks)': False, 'contains(energy)': False, 'contains(next)': False, 'contains(hmmmm)': False, 'contains(justin)': False, 'contains(chambers)': False, 'contains(basically)': False, 'contains(uncharismatic)': False, 'contains(version)': False, 'contains(chris)': False, 'contains(o)': False, 'contains(donnell)': False, 'contains(range)': False, 'contains(mena)': False, 'contains(suvari)': False, 'contains(thora)': False, 'contains(birch)': False, 'contains(dungeons)': False, 'contains(dragons)': False, 'contains(miscast)': False, 'contains(deliveries)': False, 'contains(piss)': False, 'contains(poor)': False, 'contains(ms)': False, 'contains(fault)': False, 'contains(definitely)': False, 'contains(higher)': False, 'contains(semi)': False, 'contains(saving)': False, 'contains(grace)': False, 'contains(wise)': False, 'contains(irrepressible)': False, 'contains(once)': True, 'contains(thousand)': False, 'contains(god)': False, 'contains(beg)': False, 'contains(agent)': False, 'contains(marketplace)': False, 'contains(modern)': False, 'contains(day)': True, 'contains(roles)': False, 'contains(romantic)': False, 'contains(gunk)': False, 'contains(alright)': False, 'contains(yeah)': False, 'contains(yikes)': False, 'contains(notches)': False, 'contains(fellas)': False, 'contains(blares)': False, 'contains(ear)': False, 'contains(accentuate)': False, 'contains(annoy)': False, 'contains(important)': False, 'contains(behind)': False, 'contains(recognize)': False, 'contains(epic)': False, 'contains(fluffy)': False, 'contains(rehashed)': False, 'contains(cake)': False, 'contains(created)': False, 'contains(shrewd)': False, 'contains(advantage)': False, 'contains(kung)': True, 'contains(fu)': True, 'contains(phenomenon)': False, 'contains(test)': False, 'contains(dudes)': False, 'contains(keep)': False, 'contains(reading)': False, 'contains(editing)': False, 'contains(shoddy)': False, 'contains(banal)': False, 'contains(stilted)': False, 'contains(plentiful)': False, 'contains(top)': True, 'contains(horse)': False, 'contains(carriage)': False, 'contains(stand)': False, 'contains(opponent)': False, 'contains(scampering)': False, 'contains(cut)': False, 'contains(mouseketeer)': False, 'contains(rope)': False, 'contains(tower)': False, 'contains(jumping)': False, 'contains(chords)': False, 'contains(hanging)': False, 'contains(says)': False, 'contains(14)': False, 'contains(shirt)': False, 'contains(strayed)': False, 'contains(championing)': False, 'contains(fun)': True, 'contains(stretches)': False, 'contains(atrocious)': False, 'contains(lake)': False, 'contains(reminded)': False, 'contains(school)': False, 'contains(cringe)': False, 'contains(musketeers)': False, 'contains(fat)': False, 'contains(raison)': False, 'contains(etre)': False, 'contains(numbers)': False, 'contains(hoping)': False, 'contains(packed)': False, 'contains(stuntwork)': False, 'contains(promoted)': False, 'contains(trailer)': False, 'contains(major)': False, 'contains(swashbuckling)': False, 'contains(beginning)': False, 'contains(finishes)': False, 'contains(juggling)': False, 'contains(ladders)': False, 'contains(ladder)': True, 'contains(definite)': False, 'contains(keeper)': False, 'contains(regurgitated)': False, 'contains(crap)': False, 'contains(tell)': False, 'contains(deneuve)': False, 'contains(placed)': False, 'contains(hullo)': False, 'contains(barely)': False, 'contains(ugh)': False, 'contains(small)': False, 'contains(annoyed)': False, 'contains(trash)': False, 'contains(gang)': False, 'contains(vow)': False, 'contains(stay)': False, 'contains(thank)': False, 'contains(outlaws)': False, 'contains(5)': False, 'contains(crouching)': False, 'contains(tiger)': False, 'contains(hidden)': False, 'contains(matrix)': False, 'contains(replacement)': False, 'contains(killers)': False, 'contains(6)': False, 'contains(romeo)': False, 'contains(die)': False, 'contains(shanghai)': False, 'contains(noon)': False, 'contains(remembered)': False, 'contains(dr)': False, 'contains(hannibal)': False, 'contains(lecter)': False, 'contains(michael)': False, 'contains(mann)': False, 'contains(forensics)': False, 'contains(thriller)': False, 'contains(manhunter)': False, 'contains(scottish)': False, 'contains(brian)': False, 'contains(cox)': False}\n"
     ]
    }
   ],
   "source": [
    "print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터로 정확도를 검증\n",
    "# 어떤 피처가 가장 유용했는지 검사\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      " contains(unimaginative) = True              neg : pos    =      8.3 : 1.0\n",
      "     contains(atrocious) = True              neg : pos    =      7.0 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      7.0 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      7.0 : 1.0\n",
      "        contains(neatly) = True              pos : neg    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류기를 사용하여 어떤 접미사가 가장 유용한지 알아낼 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = int(len(featuresets)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f5095ff3809a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             tree = DecisionTreeClassifier.best_stump(\n\u001b[0;32m--> 154\u001b[0;31m                 feature_names, labeled_featuresets, verbose)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             tree = DecisionTreeClassifier.best_binary_stump(\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mbest_stump\u001b[0;34m(feature_names, labeled_featuresets, verbose)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mstump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mstump_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstump\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstump_error\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mbest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstump_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, labeled_featuresets)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Decision tree:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decisions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classifier.pseudocode(depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Exploiting Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 살펴본 단어 베이스 분류기는 특정 단어가 어떤 문맥에서 어떤 품사로 쓰이는지 알 수 없다. 따라서 태깅되지 않은 문장과 타겟 단어의 인덱스를 인풋으로 넣어서 문맥에 기반한 피처 추출기를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "               \"suffix(2)\": sentence[i][-2:],\n",
    "               \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append((pos_features(untagged_sent, i), tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = int(len(featuresets)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set) # 문맥 정보를 추가하니 정확도 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 서로 관련된 인풋에 대해서 가장 적절한 레이블을 찾아 주는 joint classifier를 만들 수 있다. 일례로는 consecutive classification 또는 greedy sequence classification이 있는데, 첫 번째 인풋에 대한 레이블을 찾고 그 다음 인풋에 대해서 최적의 레이블을 찾는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "    return features\n",
    "\n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append((featureset, tag))\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents)*0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980528511821975\n"
     ]
    }
   ],
   "source": [
    "print(tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Other Methods for Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 설명된 방법의 단점은 어떤 단어를 명사로 태깅한 후, 나중에 동사인걸 알게 되어도 고칠 방법이 없다는 것이다. 이 단점을 극복하는 방법으로는 Transformational joint classifier를 만드는 방법이 있는데, 이것은 인풋에 대하여 초기값을 부여하고, 이후 인풋값의 변화에 따라 초기값을 조정하는 방식으로 작동한다. 예시로는 Brill Tagger가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법은 모든 가능한 POS태그에 점수를 부여하고, 가장 점수가 높은 시퀀스를 선택하는 것이다. 이것이 Hidden Markov Model에 적용된 방법이다. Hidden Markov Model은 consecutive classifier처럼 인풋과 여태까지 예측된 태그들 모두를 본다는 점에서 비슷하다. 하지만 주어진 단어에 대해서 최선의 태그 하나만 부여하는 것이 아니라, 확률 분포를 만들어낸다. 이 확률값은 태그 시퀀스에 대해서 확률 점수를 만들 수 있게 조합되고, 가장 확률값이 높은 태그 시퀀스가 선택되게 된다. \n",
    "하지만 30개의 태그가 있는 셋이 있다고 했을 때, 10단어로 만들어진 문장을 다 검토하는데에는 30^10의 방법이 생기게 된다. 이러한 연산의 부담을 줄이기 위하여, Hidden Markov Model은 가장 최근의 n개 태그를 보는 방법을 차용한다. 이러한 방식이 Maximum Entropy Markov Model 그리고 Linear-Chain Conditional Random Field Model에 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Further Examples of Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 문장 부호에 대한 분류 작업이라고 생각해도 좋다: 문장의 끝을 의미할 수 있는 어떤 부호에 도달했을 때, 우리는 이전 문장을 끝내는 것인지 결정해야 하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = [] # 문장에서 나온 토큰들의 리스트 \n",
    "boundaries = set() # 문장으로 구별된 모든 토큰들의 인덱스의 집합\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "           'prev-word': tokens[i-1].lower(),\n",
    "           'punct': tokens[i],\n",
    "           'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "              for i in range(1, len(tokens)-1)\n",
    "              if tokens[i] in \".?!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets)*0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in \".?!\" and classifer.classify(punct_features(words, i)) == True:\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Identifying Dialogue Act Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화문을 처리할 때는, 한 화자가 말하는 utterance = action이라고 생각할 수 있다. Dialogue act 에는 statement, emotion, ynQuestion, continuer 등이 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "              for post in posts]\n",
    "size = int(len(featuresets)*0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Recognizing Textual Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Scaling Up to Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 The Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 셋을 만들 때 고려해야 할 점 하나는 학습 데이터 셋과의 tradeoff이고, 다른 하나는 둘 간의 유사도이다. 더 비슷할수록 우리의 evaluation의 confidence가 떨어진다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import brown\n",
    "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
    "random.shuffle(tagged_sents)\n",
    "size = int(len(tagged_sents)*0.1)\n",
    "train_set, test_set = tagged_sents[size:], tagged_sents[:size]\n",
    "# 이 경우 우리의 학습 데이터와 테스트 데이터가 너무 유사해서, 다른 장르로 generalize할 수 없다\n",
    "# 또한, 학습 데이터 셋을 만들 때 random.shuffle()을 사용했기 때문에, 여기에 쓰인 데이터가 테스트 데이터에 있을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ids = brown.fileids(categories='news')\n",
    "size = int(len(file_ids)*0.1)\n",
    "train_set = brown.tagged_sents(file_ids[size:])\n",
    "test_set = brown.tagged_sents(file_ids[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 만약 더 엄격하게 나누고 싶다면, 아예 장르를 다르게 선택하면 된다\n",
    "train_set = brown.tagged_sents(categories='news')\n",
    "test_set = brown.tagged_sents(categories='fiction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-17177cefaf35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {:4.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/precisionandrecall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Precision</strong>, which indicates how many of the items that we identified were relevant, is TP/(TP+FP). <br>\n",
    "<strong>Recall</strong>, which indicates how many of the relevant items that we identified, is TP/(TP+FN). <br>\n",
    "The <strong>F-Measure</strong> (or F-Score), which combines the precision and recall to give a single score, is defined to be the harmonic mean of the precision and recall: (2 × Precision × Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix란 올바른 레이블이 i일때, [i, j]에 얼마나 j 레이블이 많이 예측되었는지를 나타낸 표이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_list(tagged_sents):\n",
    "    return [tag for sent in tagged_sents for (word, tag) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_tagger(tagger, corpus):\n",
    "    return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-fb046ccf42e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'editorial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'editorial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_percents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sohyun/anaconda/lib/python3.6/site-packages/nltk/metrics/confusionmatrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reference, test, sort_by_count)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Construct a value->index dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "t2 = nltk.BigramTagger(train_sents)\n",
    "gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
    "test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
    "cm = nltk.ConfusionMatrix(gold, test)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래의 코퍼스를 N개의 섭셋으로 나누는데, 이것을 folds라고 한다. 각각의 folds에 대해 그 fold를 제외한 모든 데이터에 대해 학습을 시킨 후, 해당 fold에 테스트한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation의 또다른 좋은 점은 각각의 학습 데이터에 대하여 성능이 얼마나 변하는지를 관찰할 수 있다는 것이다. 성능이 비슷비슷하게 나오면, 우리는 학습 모델에 대해 confidence를 어느정도 가질 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree는 인풋 값에 대하여 레이블을 선택하는 단순한 플로우차트이다. <br>\n",
    "이 플로우차트는 decision nodes (피처 값을 체크하는 것), leaf nodes (레이블을 달아주는 것)로 구성되어 있다. 또한 root node는 초기 decision node로서 한 인풋 값의 피처를 체크한 후 가지를 선택해 나가게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision stump는 하나의 node가 하나의 피처만을 고려하여 인풋들을 분류하는 Decision Tree의 일종이다. Decision Tree를 만들기 전에, 각각의 피처에 대하여 가장 최적의 Decision stump를 만들어보기로 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 피처가 가장 유용한지 판별하는 방법으로 가장 잘 쓰이는 것 중 하나가 information gain이다. Information gain은 하나의 피처로 인풋을 나누었을 때 얼마나 잘 정돈되어 나오는지를 측정한다. 초기 인풋 값이 얼마나 '덜 정돈'되어있는지 측정하려면, 우리는 레이블의 entropy를 계산한다. 여기서 entropy는 각 레이블의 확률 * 해당 레이블의 로그 확률의 총합으로 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 다음 예제를 보자\n",
    "import math\n",
    "def entropy(labels):\n",
    "    freqdist = nltk.FreqDist(labels)\n",
    "    probs = [freqdist.freq(l) for l in freqdist]\n",
    "    return -sum(p*math.log(p,2) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['male', 'male', 'male', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['male', 'female', 'male', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'male', 'female', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'female', 'male', 'female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'female', 'female', 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 초기 인풋 값의 entropy를 계산한 후, decision stump를 적용한 후에 얼마나 레이블이 정돈되는지 결정하면 된다. 이렇게 하기 위해서는, decision stump의 leaf에 대한 entropy를 각각 계산한 후, 이 entropy의 평균값을 계산한다. 여기서의 information gain은 original entropy - reduced entropy가 된다. Information gain이 클수록 decision stump의 성능이 좋아진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Decision Tree의 장점</strong><br>\n",
    "- 단순해서 이해하기 쉽다 <br>\n",
    "- 많은 위계적 분류 기준이 존재할 때 적절하게 사용할 수 있다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Decision Tree의 단점</strong>\n",
    "- 가지치기를 해나가게 될 수록, 하나의 가지가 데이터를 분리해 나가기 때문에, 결국 학습 데이터의 양이 적어지면서 overfitting의 문제가 생긴다 --> (1) 너무 학습 데이터가 적어지지 않게 node를 세부적으로 나누지 않는다 (2) full tree를 만든 후, 성능에 도움이 되지 않는 가지들은 가지치기를 한다\n",
    "- 또 하나의 문제는 tree를 만들어 나가면서 피처가 어떤 특정한 순서를 가지고 체크되어진다는 것이다 --> 피처가 서로 독립일 경우에 문제가 될 수 있다\n",
    "- 피처의 설명력이 약할 때, 보통 이러한 피처가 tree의 마지막에 나타나므로, 그때가 되면 학습 데이터가 많이 남아있지 않아서 정확히 피처가 어떤 정도의 영향을 줄 수 있는지 판단하기 어렵다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes 분류기의 경우에는 모든 피처가 주어진 인풋 값에 대해서 어떤 레이블을 가지게 될지에 대해 '같은 목소리'를 가진다. 레이블을 결정하기 위해서, naive bayes는 각 레이블의 prior probability를 계산하는데 - 이것은 학습 데이터에 있는 각 레이블의 빈도를 체크하는 것이다 - 이 과정과 각 피처가 결합하여 각 레이블의 likelihood estimate를 계산하게 되고, 이 값이 가장 큰 것이 레이블로 결정되게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Underlying Probabilistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes를 이해하는 또 다른 방법은 이 분류기가 한 인풋에 대하여 가장 '그럴듯한' 레이블을 선택한다는 것이다. 여기서의 가정은 모든 인풋값이 해당 값에 대해 레이블을 일단 선택하고 나서 서로 독립된 피처들을 생성한다는 것에 있다. 물론 이 가정은 비현실적이다 -- 피처들은 종종 서로와의 관련성이 크기 때문이다. 이러한 가정을 naive Bayes assumption (independence assumption)이라고 하는데, 이 가정으로 인해 우리는 서로 다른 피처들의 영향을 합할 수 있게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/naivebayes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Zero Counts and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(f|label), 즉 주어진 label을 가지고 있을 확률에 대한 어떤 피처 feature의 기여도를 계산하는 가장 간단한 방법은 학습 데이터 내에서 그 레이블을 가지고 있으면서 그 피처에 해당하는 instance들의 비율을 구하는 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/zerocount.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 학습 데이터 내에서 주어진 레이블에 대해 그 피처가 한번도 해당하지 않는 경우 문제가 된다. 이 경우 우리의 P(f|label) = 0 이기 때문이다. 이 경우 우리의 인풋은 이 레이블을 절대 가지지 못하게 될 것이다. 여기서 문제는 우리가 주어진 레이블에 대해서 한 인풋이 해당 피처를 가지고 있을 거라고 생각하는 데 있다. 즉, count(f)가 점점 작아질 때, 우리의 estimate의 신뢰도가 점점 떨어지게 되므로 우리는 smoothing 기법을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면, Expected Likelihood Estimation은 모든 count(f, label)값에 0.5를 더한다. 그리고 Heldout Estimation은 피처의 빈도와 피처의 확률 사이의 관계를 계산하기 위해 heldout corpus를 사용한다. 이를 위해 우리는 nltk.probability 모듈을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Non-Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 그동안 각 피처가 binary라는 것을 가정해 왔으나, 멀티클래스의 경우에도 binary로 바꾸어서 계산할 수 있다. 숫자 피처의 경우 binning을 통해 마찬가지로 계산할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또다른 방법은 회귀분석 방법을 통해서 숫자 피처의 확률을 모델링하는 방법이다. 만약 height 피처가 정규분포를 가지고 있다고 가정한다면, 우리는 mean과 variance를 계산해서 P(height|label)을 구할 수 있을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 The Naivete of Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive Bayes가 naive인 이유는 모든 피처가 독립이라고 가정하는 것이 말이 안되기 때문이다. 하지만 현실에서 서로 독립이 아닌 피처들을 피하기란 매우 어렵다. 그런데 만약 naive bayes에서 독립 가정을 무시한다면? 분류기는 서로 관련이 높은 피처들의 효과를 \"double counting\"하게 될 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "물론 우리가 분류기를 만들 때에는 똑같은 피처들을 사용하지 않지만, 대부분의 경우 서로 관련이 있는 피처들을 사용하므로, 겹치는 정보량이 많아질 경우 bias가 생길 수 있음을 유의해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 The Cause of Double-Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-counting의 문제는 학습 과정 중에 피처의 기여도가 각각 계산되는데, 분류기를 사용하여 새로운 인풋에 대한 레이블을 주게 될 때에는 이러한 피처들이 합해진다는 데 있다. 해결책은 학습 과정 중에 피처들 사이의 상호작용을 고려하는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/parametersandweights.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes에서는 parameter와 weight를 독립적으로 세팅한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Maximum Entropy Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum entropy는 naive bayes와 유사하지만 모델의 parameter를 정희하기 위해 확률을 사용하는 것이 아니라 분류기의 성능을 최대로 하기 위하여 search 테크닉을 사용한다. 즉, 학습 코퍼스의 total likelihood를 최대화하기 위한 parameter set을 찾는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 피처들 간의 상호작용 때문에 직접적으로 학습 데이터의 likelihood를 최대화할 수 있는 parameter를 계산하는 것은 불가능하다. 따라서 maximum entropy 분류기는 iterative optimization 테크닉을 사용한다. 즉, 처음에 parameter의 초기값을 random value로 정의하고 나서 최적화 프로세스를 통해 재설정하는 것이다. 여기서의 문제점은 이 과정이 오래 걸릴 수 있다는 것인데, 학습 데이터 셋이 크거나, 피처의 수가 많거나, 레이블이 많을때 특히 더 그러하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 The Maximum Entropy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes처럼 maximum entropy 모델도 가능한 parameter들을 곱하여 레이블의 likelihood를 계산하는것은 유사하다. 하지만 maximum enropy 분류기는 유저로 하여금 어떤 레이블과 피처의 조합을 parameter로 받을 것인지 결정하게끔 한다. 이 조합을 joint feature라고 부른다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Maximizing Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음의 예를 통해 entropy maximization을 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/maxentropy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 주어진 단어에 대해 올바른 word sense를 골라야 한다고 해보자. 이럴 때 가능한 확률 분포는 굉장히 많을 것이다. 위 테이블은 이중 세개를 나열하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 세 개의 분포 중 어느 것도 가능할 수 있겠지만, 우리는 아마 (i)를 선택할 것이다. 왜냐하면 10개의 sense에 대하여 확률이 고르게 분포되어 있기 때문에 - 즉 entropy가 다른 두 개보다 더 높기 때문이다. 이런 방식으로 우리가 joint feature를 고를 때에는 empirifcal frequency가 더 높은 것을 고르는 것이 일반적이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Generative vs Conditional Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes와 maximum entropy의 가장 중요한 차이점은 naive bayes는 generative 분류기이고, maximum entropy는 conditional 분류기라는 것이다. \n",
    "- What is the most likely label for a given input?\n",
    "- How likely is a given label for a given input?\n",
    "- What is the most likely input value?\n",
    "- How likely is a given input value?\n",
    "- How likely is a given input value with a given label?\n",
    "- What is the most likely label for an input that might have one of two values (but we don't know which)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Generative</strong> P(input, label) 즉 (input, label) 쌍의 joint probability를 구한다.<br>\n",
    "<strong>Conditional</strong> P(label|input) 즉 input이 주어졌을 때 label의 확률을 구한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Modeling Linguistic Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류기는 자연어에서 나타나는 언어적 패턴을 이해하는 데 도움을 준다. 우리는 이러한 패턴을 캡처하여 모델을 만들 수 있다. 또한 이러한 모델을 사용하여 새로운 언어 데이터에 대한 예측을 할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 What Do Models Tell Us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Descriptive Models</strong> 왜 데이터가 어떤 패턴을 가지고 있는지 정보를 알 수 없는 패턴들을 캡처한다. <br>\n",
    "<strong>Explanatory Models</strong> 특정 언어적 패턴의 이유가 되는 특징과 관계를 캡처하고자 시도한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modeling the linguistic data found in corpora can help us to understand linguistic patterns, and can be used to make predictions about new language data.\n",
    "- Supervised classifiers use labeled training corpora to build models that predict the label of an input based on specific features of that input.\n",
    "- Supervised classifiers can perform a wide variety of NLP tasks, including document classification, part-of-speech tagging, sentence segmentation, dialogue act type identification, and determining entailment relations, and many other tasks.\n",
    "- When training a supervised classifier, you should split your corpus into three datasets: a training set for building the classifier model; a dev-test set for helping select and tune the model's features; and a test set for evaluating the final model's performance.\n",
    "- When evaluating a supervised classifier, it is important that you use fresh data, that was not included in the training or dev-test set. Otherwise, your evaluation results may be unrealistically optimistic.\n",
    "- Decision trees are automatically constructed tree-structured flowcharts that are used to assign labels to input values based on their features. Although they're easy to interpret, they are not very good at handling cases where feature values interact in determining the proper label.\n",
    "- In naive Bayes classifiers, each feature independently contributes to the decision of which label should be used. This allows feature values to interact, but can be problematic when two or more features are highly correlated with one another.\n",
    "- Maximum Entropy classifiers use a basic model that is similar to the model used by naive Bayes; however, they employ iterative optimization to find the set of feature weights that maximizes the probability of the training set.\n",
    "- Most of the models that are automatically constructed from a corpus are descriptive — they let us know which features are relevant to a given patterns or construction, but they don't give any information about causal relationships between those features and patterns."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
